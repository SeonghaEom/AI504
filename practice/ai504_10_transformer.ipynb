{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE_MQj2V-mAD"
   },
   "source": [
    "# [AI 504] Programming for AI, Fall 2021\n",
    "# Practice 10: Transformers\n",
    "----- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okJXS1-OEbN7"
   },
   "source": [
    "#### [Notifications]\n",
    "- If you have any questions, feel free to ask\n",
    "- For additional questions, send emails: dyan.lee@kaist.ac.kr    \n",
    "      \n",
    "\n",
    "     \n",
    "     \n",
    "# Table of contents\n",
    "1. [Prepare input](#1)\n",
    "2. [Implement Transformer](#2)\n",
    "3. [Train and Evaluate](#3)\n",
    "4. [Visualize attention](#4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2Bj-rF9EbN7"
   },
   "source": [
    "# Prepare essential packages"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 15,
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
   "metadata": {
    "id": "nHrI30vIEbN7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Collecting torchtext==0.14.0\n",
      "  Downloading torchtext-0.14.0-cp39-cp39-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch==1.13.0\n",
      "  Downloading torch-1.13.0-cp39-cp39-manylinux1_x86_64.whl (890.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 890.2 MB 13 kB/s  eta 0:00:012     |██████████████████              | 503.2 MB 9.8 MB/s eta 0:00:40     |█████████████████████████▎      | 703.3 MB 8.6 MB/s eta 0:00:22     |████████████████████████████▌   | 791.7 MB 8.6 MB/s eta 0:00:12\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from torchtext==0.14.0) (4.64.0)\n",
      "Requirement already satisfied: numpy in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from torchtext==0.14.0) (1.22.3)\n",
      "Requirement already satisfied: requests in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from torchtext==0.14.0) (2.27.1)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 317.1 MB 44 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from torch==1.13.0->torchtext==0.14.0) (4.1.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 8.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 557.1 MB 12 kB/s  eta 0:00:012     |███████████████████████▌        | 408.3 MB 8.8 MB/s eta 0:00:18\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[K     |████████████████████████████████| 849 kB 9.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchtext==0.14.0) (61.2.0)\n",
      "Requirement already satisfied: wheel in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchtext==0.14.0) (0.37.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests->torchtext==0.14.0) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests->torchtext==0.14.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests->torchtext==0.14.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests->torchtext==0.14.0) (1.26.9)\n",
      "Installing collected packages: nvidia-cublas-cu11, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, torch, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.0\n",
      "    Uninstalling torch-1.9.0:\n",
      "      Successfully uninstalled torch-1.9.0\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.10.0\n",
      "    Uninstalling torchtext-0.10.0:\n",
      "      Successfully uninstalled torchtext-0.10.0\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.0 torchtext-0.14.0\n",
      "fatal: destination path 'attentionviz' already exists and is not an empty directory.\n",
=======
      "Requirement already satisfied: torchtext==0.10.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (0.10.0)\n",
      "Requirement already satisfied: torch==1.9.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from torchtext==0.10.0) (1.9.0)\n",
      "Requirement already satisfied: tqdm in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from torchtext==0.10.0) (4.64.0)\n",
      "Requirement already satisfied: requests in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from torchtext==0.10.0) (2.27.1)\n",
      "Requirement already satisfied: numpy in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from torchtext==0.10.0) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests->torchtext==0.10.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests->torchtext==0.10.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests->torchtext==0.10.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests->torchtext==0.10.0) (1.26.9)\n",
      "fatal: 대상 경로가('attentionviz') 이미 있고 빈 디렉터리가 아닙니다.\n",
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
      "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
      "Collecting de-core-news-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n",
<<<<<<< HEAD
      "\u001b[K     |████████████████████████████████| 14.6 MB 7.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from de-core-news-sm==3.4.0) (3.4.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.22.3)\n",
      "Requirement already satisfied: setuptools in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (61.2.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.10.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.27.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: jinja2 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.5)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.1)\n",
=======
      "\u001b[K     |████████████████████████████████| 14.6 MB 535 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from de-core-news-sm==3.4.0) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.21.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.10.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: setuptools in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (61.2.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: jinja2 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.11.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.1)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.4.0\n",
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
<<<<<<< HEAD
      "\u001b[K     |████████████████████████████████| 12.8 MB 269 kB/s eta 0:00:01    |█████▊                          | 2.3 MB 8.3 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from en-core-web-sm==3.4.1) (3.4.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.22.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.0)\n",
      "Requirement already satisfied: setuptools in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (61.2.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n",
      "Requirement already satisfied: jinja2 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: spacy in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (3.4.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (0.10.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: setuptools in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: jinja2 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (8.1.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from spacy) (1.22.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/seongha/\u001b[A\u001b[B\u001b[B/envs/LTML/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n"
=======
      "\u001b[K     |████████████████████████████████| 12.8 MB 260 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from en-core-web-sm==3.4.1) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.27.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.0)\n",
      "Requirement already satisfied: setuptools in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (61.2.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.4.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: spacy in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (3.4.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: jinja2 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (0.10.0)\n",
      "Requirement already satisfied: setuptools in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from spacy) (8.1.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n"
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
<<<<<<< HEAD
    "!pip install torchtext==0.14.0\n",
=======
    "!pip install torchtext==0.10.0\n",
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
    "!git clone https://github.com/sjpark9503/attentionviz.git\n",
    "!python -m spacy download de\n",
    "!python -m spacy download en\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sayXpp8FEbN8"
   },
   "source": [
    "# I. Prepare input\n",
    "<a id='1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KWOpLYfEbN8"
   },
   "source": [
    "We've already learned how to preprocess the text data in week 8, 9 & 10.\n",
    "\n",
    "You can see some detailed explanation about translation datasets in [torchtext](https://pytorch.org/text/), [practice session,week 9](https://classum.com/main/course/7726/103) and [PyTorch NMT tutorial](https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "kaduS25kEbN8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seonghaeom/anaconda3/lib/python3.9/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"de\" could not be loaded, trying \"de_core_news_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n",
      "/home/seonghaeom/anaconda3/lib/python3.9/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "SRC = Field(tokenize = \"spacy\",\n",
    "            tokenizer_language=\"de\",\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            batch_first=True,\n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = \"spacy\",\n",
    "            tokenizer_language=\"en\",\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            batch_first=True,\n",
    "            lower = True)\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'),\n",
    "                                                    fields = (SRC, TRG), \n",
    "                                                    train='train',\n",
    "                                                    validation='val', \n",
    "                                                    test ='test_2016_flickr')\n",
    "\n",
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fE_u1Qg-EbN8"
   },
   "source": [
    "# II. Implement Transformer\n",
    "<a id='2'></a>\n",
    "In practice week 11, we will learn how to implement the __[Attention is all you need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) (Vaswani et al., 2017)__\n",
    "\n",
    "The overall architecutre is as follows:\n",
    "![picture](http://incredible.ai/assets/images/transformer-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqEVVfl-EbN8"
   },
   "source": [
    "## 1. Basic building blocks\n",
    "\n",
    "In this sections, we will implement the building blocks of the transformer: [Multi-head attention](#1a), [Position wise feedforward network](#1b) and [Positional encoding](#1c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeI2oINrEbN8"
   },
   "source": [
    "### a. Attention\n",
    "<a id='1a'></a>\n",
    "In this section, you will implement scaled dot-product attention and multi-head attention.\n",
    "\n",
    "__Scaled dot product:__\n",
    "\n",
    "![picture](http://incredible.ai/assets/images/transformer-scaled-dot-product.png)\n",
    "\n",
    "__Multi-head attention:__\n",
    "\n",
    "![picture](http://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png)\n",
    "Equation:\n",
    "\n",
    "$$\\begin{align} \\text{MultiHead}(Q, K, V) &= \\text{Concat}(head_1, ...., head_h) W^O \\\\\n",
    "\\text{where head}_i &= \\text{Attention} \\left( QW^Q_i, K W^K_i, VW^v_i \\right)\n",
    "\\end{align}$$\n",
    "\n",
    "__Query, Key and Value projection:__\n",
    "\n",
    "![picture](http://jalammar.github.io/images/t/self-attention-matrix-calculation.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "07AkqQcqEbN8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "# from einops import rearrange\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        emb_dim,\n",
    "        num_heads,\n",
    "        dropout=0.0,\n",
    "        bias=False,\n",
    "        encoder_decoder_attention=False,  # False: encoder self-attention/ True: decoder cross attention\n",
    "        causal = False # (causal) masked attention\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = emb_dim // num_heads\n",
    "        assert self.head_dim * num_heads == self.emb_dim, \"emb_dim must be divisible by num_heads\"\n",
    "\n",
    "        self.encoder_decoder_attention = encoder_decoder_attention\n",
    "        self.causal = causal\n",
    "        self.k_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        self.v_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        self.q_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        self.out_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        \"\"\"\n",
    "        To-Do : Reshape input\n",
    "          Args : batch_size X sequence_length X embedding dimension\n",
    "          Return : batch_size X # attention head X sequence_length X head dimension\n",
    "        \"\"\"\n",
    "        new_sh = x.shape[:-1] + (self.num_heads, self.head_dim)\n",
    "        x = x.view(*new_sh)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "        # This is equivalent to\n",
    "        # return x.transpose(1,2)\n",
    "    \n",
    "    def scaled_dot_product(self, \n",
    "                           query: torch.Tensor, \n",
    "                           key: torch.Tensor, \n",
    "                           value: torch.Tensor,\n",
    "                           attention_mask: torch.BoolTensor):\n",
    "        \"\"\"\n",
    "        To-Do : Implement scaled dot product\n",
    "          Args:\n",
    "            Query (Tensor): shape `(batch, seq_len, emb_dim)`\n",
    "            Key (Tensor): shape `(batch, seq_len, emb_dim)`\n",
    "            Value (Tensor): shape `(batch, seq_len, emb_dim)`\n",
    "            attention_mask: binary BoolTensor of shape `(batch, seq_len)` or `(seq_len, seq_len)`\n",
    "\n",
    "          Returns:\n",
    "            attn_output : attended output (result of attention mechanism)\n",
    "            attn_weights: value of each attention\n",
    "        \"\"\"\n",
    "        attn_weights = torch.matmul(query, torch.transpose(key, -1, -2)) / math.sqrt(self.emb_dim)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(1), float(\"-inf\"))\n",
    "\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)  # softmax(QK^T/sqrt(d))\n",
    "        attn_probability = F.dropout(attn_weights, p=self.dropout, training=True)\n",
    "        attn_output = torch.matmul(attn_probability, value)\n",
    "        return attn_output, attn_weights\n",
    "    \n",
    "    def MultiHead_scaled_dot_product(self, \n",
    "                       query: torch.Tensor, \n",
    "                       key: torch.Tensor, \n",
    "                       value: torch.Tensor,\n",
    "                       attention_mask: torch.BoolTensor):\n",
    "        \"\"\"\n",
    "        To-Do : Implement Multi-head version of scaled dot product, please also take the causal masking into account.\n",
    "          Args:\n",
    "            Query (Tensor): shape `(batch,# attention head, seq_len, head_dim)`\n",
    "            Key (Tensor): shape `(batch,# attention head, seq_len, head_dim)`\n",
    "            Value (Tensor): shape `(batch,# attention head, seq_len, head_dim)`\n",
    "            attention_mask: binary BoolTensor of shape `(batch, src_len)` or `(seq_len, seq_len)`\n",
    "\n",
    "          Returns:\n",
    "            attn_output : attended output (result of attention mechanism)\n",
    "            attn_weights: value of each attention\n",
    "        \"\"\"\n",
    "        ##scaled dot product\n",
    "        attn_weights = torch.matmul(query, torch.transpose(key, -1, -2)) / math.sqrt(self.emb_dim)\n",
    "        \n",
    "        # Attention mask\n",
    "        if attention_mask is not None:\n",
    "            if self.causal:\n",
    "              # (seq_len x seq_len)\n",
    "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(0).unsqueeze(1), float(\"-inf\"))\n",
    "            else:\n",
    "              # (batch_size x seq_len)\n",
    "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(1).unsqueeze(2), float(\"-inf\"))\n",
    "\n",
    "\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "        attn_probability = F.dropout(attn_weights, p=self.dropout, training=True)\n",
    "        attn_output = torch.matmul(attn_probability, value)\n",
    "\n",
    "        ## concat multiheads\n",
    "        attn_output = attn_output.permute(0,2,1,3).contiguous()\n",
    "        concat_attn_output_shape = attn_output.size()[:-2] + (self.emb_dim,)\n",
    "        attn_output = attn_output.view(*concat_attn_output_shape)\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        query: torch.Tensor,\n",
    "        key: torch.Tensor,\n",
    "        attention_mask: torch.Tensor = None,\n",
    "        ):\n",
    "        q = self.q_proj(query)\n",
    "        # Enc-Dec attention\n",
    "        if self.encoder_decoder_attention:\n",
    "            k = self.k_proj(key)\n",
    "            v = self.v_proj(key)\n",
    "        # Self attention\n",
    "        else:\n",
    "            k = self.k_proj(query)\n",
    "            v = self.v_proj(query)\n",
    "\n",
    "        q = self.transpose_for_scores(q)\n",
    "        k = self.transpose_for_scores(k)\n",
    "        v = self.transpose_for_scores(v)\n",
    "\n",
    "        attn_output, attn_weights = self.MultiHead_scaled_dot_product(q,k,v,attention_mask)\n",
    "        return attn_output, attn_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b528gtwHEbN8"
   },
   "source": [
    "### b. Position-wise feed forward network\n",
    "<a id='1b'></a>\n",
    "In this section, we will implement position-wise feed forward network\n",
    "\n",
    "$$\\text{FFN}(x) = \\max \\left(0, x W_1 + b_1 \\right) W_2 + b_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sBqWWdIyEbN8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim: int, d_ff: int, dropout: float = 0.1):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.w_1 = nn.Linear(emb_dim, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, emb_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        To-Do : Implement position-wise feed forward network\n",
    "          Args:\n",
    "            x (Tensor): input to the layer of shape `(batch, seq_len, emb_dim)`\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        x = self.activation(self.w_1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.w_2(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9-qkoUKEbN8"
   },
   "source": [
    "### c. Sinusoidal Positional Encoding\n",
    "<a id='1c'></a>\n",
    "In this section, we will implement sinusoidal positional encoding\n",
    "\n",
    "$$\\begin{align}\n",
    "PE(pos, 2i) &= \\sin \\left( pos / 10000^{2i / d_{model}} \\right)  \\\\\n",
    "PE(pos, 2i+1) &= \\cos \\left( pos / 10000^{2i / d_{model}} \\right)  \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tsiJalEvEbN8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SinusoidalPositionalEmbedding(nn.Embedding):\n",
    "    def __init__(self, num_positions, embedding_dim, padding_idx=None):\n",
    "        super().__init__(num_positions, embedding_dim)\n",
    "        self.weight = self._init_weight(self.weight)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _init_weight(out: nn.Parameter):\n",
    "        n_pos, embed_dim = out.shape\n",
    "        pe = nn.Parameter(torch.zeros(out.shape))\n",
    "        for pos in range(n_pos):\n",
    "            for i in range(0, embed_dim, 2):\n",
    "              \"\"\"\n",
    "              To-Do : Implement sinusoidal positional encoding\n",
    "              \"\"\"\n",
    "              pe[pos, i].data.copy_(torch.tensor(np.sin(pos / 10000**(i/embed_dim))))\n",
    "              pe[pos, i+1].data.copy_(torch.tensor(np.cos(pos / 10000**(i + 1 / embed_dim))))\n",
    "        pe.detach_()\n",
    "                \n",
    "        return pe\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input_ids):\n",
    "        bsz, seq_len = input_ids.shape[:2]\n",
    "        positions = torch.arange(seq_len, dtype=torch.long, device=self.weight.device)\n",
    "        return super().forward(positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdhwI3hPEbN8"
   },
   "source": [
    "## 2. Transformer Encoder\n",
    "\n",
    "Now we have all basic building blocks which are essential to build Transformer. \n",
    "\n",
    "Let's implement Transformer step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6ym2hKzEbN8"
   },
   "source": [
    "### a. Encoder layer\n",
    "In this section, we will implement single layer of Transformer encoder.\n",
    "![picture](https://www.researchgate.net/publication/334288604/figure/fig1/AS:778232232148992@1562556431066/The-Transformer-encoder-structure.ppm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6B93kjUlEbN8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.emb_dim = config.emb_dim\n",
    "        self.ffn_dim = config.ffn_dim\n",
    "        self.self_attn = MultiHeadAttention(            \n",
    "            emb_dim=self.emb_dim,\n",
    "            num_heads=config.attention_heads, \n",
    "            dropout=config.attention_dropout)\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "        self.dropout = config.dropout\n",
    "        self.activation_fn = nn.ReLU()\n",
    "        self.PositionWiseFeedForward = PositionWiseFeedForward(self.emb_dim, self.ffn_dim, config.dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "\n",
    "    def forward(self, x, encoder_padding_mask):\n",
    "        \"\"\"\n",
    "        To-Do : Implement transformer encoder layer\n",
    "          Args:\n",
    "            x (Tensor): input to the layer of shape `(batch, seq_len, emb_dim)`\n",
    "            encoder_padding_mask: binary BoolTensor of shape `(batch, src_len)`\n",
    "\n",
    "          Returns:\n",
    "            x : encoded output of shape `(batch, seq_len, emb_dim)`\n",
    "            self_attn_weights: self attention score\n",
    "        \"\"\"\n",
    "        ## residual\n",
    "        residual = x\n",
    "        ## MHA\n",
    "        x, attn_weights = self.self_attn(query=x, key=x, attention_mask=encoder_padding_mask)\n",
    "        x  = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        ## layer norm\n",
    "        x = self.self_attn_layer_norm(x)\n",
    "\n",
    "        ## position wise FFW\n",
    "        x = self.PositionWiseFeedForward(x)\n",
    "        ## layer norm\n",
    "        x = self.final_layer_norm(x)\n",
    "\n",
    "\n",
    "        ## clamping , for preventing gradient explosion\n",
    "        if torch.isinf(x).any() or torch.isnan(x).any():\n",
    "          clamp_value = torch.finfo(x.dtype).max - 1000\n",
    "          x = torch.clamp(x, min=-clamp_value, max=clamp_value)\n",
    "\n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LygNGzM0EbN8"
   },
   "source": [
    "### b. Encoder\n",
    "\n",
    "Stack encoder layers and build full Transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nZOAlAv7EbN8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config, embed_tokens):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = config.dropout\n",
    "\n",
    "        emb_dim = embed_tokens.embedding_dim\n",
    "        self.padding_idx = embed_tokens.padding_idx\n",
    "        self.max_source_positions = config.max_position_embeddings\n",
    "\n",
    "        self.embed_tokens = embed_tokens\n",
    "        self.embed_positions = SinusoidalPositionalEmbedding(\n",
    "                config.max_position_embeddings, config.emb_dim, self.padding_idx\n",
    "            )\n",
    "\n",
    "        self.layers = nn.ModuleList([EncoderLayer(config) for _ in range(config.encoder_layers)])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \"\"\"\n",
    "        To-Do : Implement the transformer encoder\n",
    "          Args:\n",
    "            input_ids (Tensor): input to the layer of shape `(batch, seq_len)`\n",
    "            attention_mask: binary BoolTensor of shape `(batch, src_len)`\n",
    "\n",
    "          Returns:\n",
    "            x: encoded output of shape `(batch, seq_len, emb_dim)`\n",
    "            self_attn_scores: a list of self attention score of each layer\n",
    "        \"\"\"\n",
    "        ## input embeds\n",
    "        inputs_embeds = self.embed_tokens(input_ids)\n",
    "        embed_pos = self.embed_positions(input_ids)\n",
    "        x = inputs_embeds + embed_pos\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        ## encoding\n",
    "        self_attn_scores = []\n",
    "        for encoder_layer in self.layers:\n",
    "          x, attn = encoder_layer(x, attention_mask)\n",
    "          self_attn_scores.append(attn.detach())\n",
    "\n",
    "        return x, self_attn_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgjqDJnKEbN8"
   },
   "source": [
    "## 3. Transformer Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73LEB0mBEbN8"
   },
   "source": [
    "### a.Decoder layer\n",
    "In this section, we will implement single layer of Transformer decoder.\n",
    "![picture](http://incredible.ai/assets/images/transformer-decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-HgMu2QCEbN8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.emb_dim = config.emb_dim\n",
    "        self.ffn_dim = config.ffn_dim\n",
    "        ##1\n",
    "        self.self_attn = MultiHeadAttention(\n",
    "            emb_dim=self.emb_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout,\n",
    "            causal=True,\n",
    "        )\n",
    "        self.dropout = config.dropout\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "        ##2\n",
    "        self.encoder_attn = MultiHeadAttention(\n",
    "            emb_dim=self.emb_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout,\n",
    "            encoder_decoder_attention=True,\n",
    "        )\n",
    "        self.encoder_attn_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "        ## 3\n",
    "        self.PositionWiseFeedForward = PositionWiseFeedForward(self.emb_dim, self.ffn_dim, config.dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        encoder_hidden_states,\n",
    "        encoder_attention_mask=None,\n",
    "        causal_mask=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        To-Do : Implement the transformer decoder layer\n",
    "          Args:\n",
    "            x (Tensor): input to the layer of shape `(batch, seq_len, emb_dim)`\n",
    "            encoder_hidden_states: output from the encoder, used for\n",
    "                encoder-side attention\n",
    "            encoder_attention_mask: binary BoolTensor of shape `(batch, src_len)` to mask out encoder padding\n",
    "            causal_mask: binary BoolTensor of shape `(batch, src_len)` to mask out future tokens in decoder.\n",
    "\n",
    "\n",
    "          Returns:\n",
    "            x: decoded output of shape `(batch, seq_len, emb_dim)`\n",
    "            self_attn_weights: self attention score\n",
    "            cross_attn_weights: encoder-decoder attention score\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        ## Masked causal (Self) attention \n",
    "        residual = x ## residual\n",
    "        x, self_attn_weights = self.self_attn(query=x, key=x, attention_mask=causal_mask)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = x+residual\n",
    "        self.self_attn_layer_norm(x)\n",
    "\n",
    "        ## Cross attention\n",
    "        residual = x #residual\n",
    "        x, cross_attn_weights = self.encoder_attn(query=x, key=encoder_hidden_states, attention_mask=encoder_attention_mask)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = x+residual\n",
    "        self.encoder_attn_layer_norm(x)\n",
    "\n",
    "        ## position wise FFW\n",
    "        x = self.PositionWiseFeedForward(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "\n",
    "        return (\n",
    "            x,\n",
    "            self_attn_weights,\n",
    "            cross_attn_weights,\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAJQ-q5mEbN8"
   },
   "source": [
    "### b. Decoder\n",
    "\n",
    "Stack decoder layers and build full Transformer decoder.\n",
    "\n",
    "Unlike the encoder, you need to do one more job: pass the causal(unidirectional) mask to the decoder self attention layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gEMa6owhEbN8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer decoder consisting of *config.decoder_layers* layers. Each layer is a :class:`DecoderLayer`\n",
    "\n",
    "    Args:\n",
    "        config: BartConfig\n",
    "        embed_tokens (torch.nn.Embedding): output embedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, embed_tokens: nn.Embedding):\n",
    "        super().__init__()\n",
    "        self.dropout = config.dropout\n",
    "        self.padding_idx = embed_tokens.padding_idx\n",
    "        self.max_target_positions = config.max_position_embeddings\n",
    "        self.embed_tokens = embed_tokens\n",
    "        self.embed_positions = SinusoidalPositionalEmbedding(\n",
    "            config.max_position_embeddings, config.emb_dim, self.padding_idx\n",
    "        )\n",
    "        self.layers = nn.ModuleList([DecoderLayer(config) for _ in range(config.decoder_layers)])  # type: List[DecoderLayer]\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        encoder_hidden_states,\n",
    "        encoder_attention_mask,\n",
    "        decoder_causal_mask,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        To-Do : Implement the transformer decoder\n",
    "\n",
    "        Args:\n",
    "            input_ids (LongTensor): previous decoder outputs of shape\n",
    "                `(batch, tgt_len)`, for teacher forcing\n",
    "            encoder_hidden_states: output from the encoder, used for\n",
    "                encoder-side attention\n",
    "            encoder_attention_mask: binary BoolTensor of shape `(batch, src_len)` to mask out encoder padding\n",
    "            causal_mask: binary BoolTensor of shape `(batch, src_len)` to mask out future tokens in decoder.\n",
    "\n",
    "          Returns:\n",
    "            x: decoded output of shape `(batch, seq_len, emb_dim)`\n",
    "            cross_attn_scores: list of encoder-decoder attention score of each layer\n",
    "        \"\"\"\n",
    "        ## positional embedding\n",
    "        positions = self.embed_positions(input_ids)\n",
    "        x = self.embed_tokens(input_ids)\n",
    "        x += positions\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # decode\n",
    "        cross_attention_scores = []\n",
    "        for idx, decoder_layer in enumerate(self.layers):\n",
    "          x, layer_self_attn, layer_cross_attn = decoder_layer(x=x,\n",
    "              encoder_hidden_states=encoder_hidden_states,\n",
    "              encoder_attention_mask=encoder_attention_mask,\n",
    "              causal_mask=decoder_causal_mask\n",
    "          )\n",
    "          cross_attention_scores.append(layer_cross_attn.detach())\n",
    "\n",
    "        return x, cross_attention_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr0g3oeIEbN8"
   },
   "source": [
    "## 4. Transformer\n",
    "\n",
    "Let's combine encoder and decoder in one place!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "M4aZzq8GEbN8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, SRC,TRG,config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.SRC = SRC\n",
    "        self.TRG = TRG\n",
    "        \n",
    "        self.enc_embedding = nn.Embedding(len(SRC.vocab), config.emb_dim, padding_idx=SRC.vocab.stoi['<pad>'])\n",
    "        self.dec_embedding = nn.Embedding(len(TRG.vocab), config.emb_dim, padding_idx=TRG.vocab.stoi['<pad>'])\n",
    "\n",
    "        self.encoder = Encoder(config, self.enc_embedding)\n",
    "        self.decoder = Decoder(config, self.dec_embedding)\n",
    "        \n",
    "        self.prediction_head = nn.Linear(config.emb_dim,len(TRG.vocab))\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def generate_mask(self,src,trg):\n",
    "        \"\"\"\n",
    "        To-Do : Generate mask for encoder and decoder attention.\n",
    "\n",
    "        Args:\n",
    "            src(LongTensor): Input to the transformer of shape (batch_size, seq_len)  \n",
    "            trg(LongTensor): Decoding target of the transformer of shape (batch_size, seq_len)  \n",
    "\n",
    "          Returns:\n",
    "            enc_attention_mask: padding mask for encoder\n",
    "            dec_attention_mask: causal mask for decoder\n",
    "        \"\"\"\n",
    "        # Mask encoder attention to ignore padding\n",
    "        enc_attention_mask = src.eq(SRC.vocab.stoi['<pad>']).to(device) # torch.Size([128, 25])\n",
    "        # Mask decoder attention for causality\n",
    "        tmp = torch.ones(trg.size(1), trg.size(1), dtype=torch.bool) # torch.Size([28, 28])\n",
    "        mask = torch.arange(tmp.size(-1)) # torch.Size([28])\n",
    "        dec_attention_mask = tmp.masked_fill_(mask < (mask + 1).view(tmp.size(-1), 1), False).to(device) # torch.Size([28, 28])\n",
    "        return enc_attention_mask, dec_attention_mask\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "                else:\n",
    "                    nn.init.constant_(param.data, 0)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        src,\n",
    "        trg,\n",
    "    ):\n",
    "        enc_attention_mask, dec_causal_mask = self.generate_mask(src, trg)\n",
    "        encoder_output, encoder_attention_scores = self.encoder(\n",
    "                input_ids=src,\n",
    "                attention_mask=enc_attention_mask\n",
    "            )\n",
    "\n",
    "        # decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\n",
    "        decoder_output, decoder_attention_scores = self.decoder(\n",
    "            trg,\n",
    "            encoder_output,\n",
    "            encoder_attention_mask=enc_attention_mask,\n",
    "            decoder_causal_mask=dec_causal_mask,\n",
    "        )\n",
    "        decoder_output = self.prediction_head(decoder_output)\n",
    "\n",
    "        return decoder_output, encoder_attention_scores, decoder_attention_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WU-llE39EbN8"
   },
   "source": [
    "# III. Train & Evaluate\n",
    "<a id='3'></a>\n",
    "This section is very similar to week 9, so please refer to it for detailed description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZRMlUmxEbN8"
   },
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easydict in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (1.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BlIc_VKaEbN8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "config = easydict.EasyDict({\n",
    "    \"emb_dim\":64,\n",
    "    \"ffn_dim\":256,\n",
    "    \"attention_heads\":4,\n",
    "    \"attention_dropout\":0.0,\n",
    "    \"dropout\":0.2,\n",
    "    \"max_position_embeddings\":512,\n",
    "    \"encoder_layers\":3,\n",
    "    \"decoder_layers\":3,\n",
    "    \n",
    "})\n",
    "\n",
    "N_EPOCHS = 100\n",
    "learning_rate = 5e-4\n",
    "CLIP = 1\n",
    "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "\n",
    "model = Transformer(SRC,TRG,config)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "            \n",
    "best_valid_loss = float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hql5wOKEbN8"
   },
   "source": [
    "## 2. Train & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "F1HHCxXuEbN8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:05<08:28,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 7.461 | Train PPL: 1738.721\n",
      "\t Val. Loss: 5.702 |  Val. PPL: 299.444\n"
     ]
<<<<<<< HEAD
=======
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:10<08:17,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 5.347 | Train PPL: 209.995\n",
      "\t Val. Loss: 5.041 |  Val. PPL: 154.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:15<08:10,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 4.849 | Train PPL: 127.664\n",
      "\t Val. Loss: 4.452 |  Val. PPL:  85.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:20<08:06,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 4.384 | Train PPL:  80.119\n",
      "\t Val. Loss: 4.113 |  Val. PPL:  61.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:25<08:03,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 4.145 | Train PPL:  63.144\n",
      "\t Val. Loss: 3.928 |  Val. PPL:  50.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:30<07:58,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 4.003 | Train PPL:  54.778\n",
      "\t Val. Loss: 3.808 |  Val. PPL:  45.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:35<07:55,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.897 | Train PPL:  49.259\n",
      "\t Val. Loss: 3.721 |  Val. PPL:  41.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:40<07:51,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.806 | Train PPL:  44.952\n",
      "\t Val. Loss: 3.633 |  Val. PPL:  37.830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:45<07:47,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.727 | Train PPL:  41.539\n",
      "\t Val. Loss: 3.566 |  Val. PPL:  35.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:51<07:42,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.661 | Train PPL:  38.894\n",
      "\t Val. Loss: 3.496 |  Val. PPL:  32.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:56<07:38,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.602 | Train PPL:  36.661\n",
      "\t Val. Loss: 3.449 |  Val. PPL:  31.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [01:01<07:33,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.547 | Train PPL:  34.722\n",
      "\t Val. Loss: 3.402 |  Val. PPL:  30.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [01:06<07:28,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.494 | Train PPL:  32.919\n",
      "\t Val. Loss: 3.337 |  Val. PPL:  28.140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [01:11<07:23,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.442 | Train PPL:  31.236\n",
      "\t Val. Loss: 3.287 |  Val. PPL:  26.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [01:16<07:18,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.393 | Train PPL:  29.770\n",
      "\t Val. Loss: 3.232 |  Val. PPL:  25.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [01:22<07:12,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.346 | Train PPL:  28.392\n",
      "\t Val. Loss: 3.196 |  Val. PPL:  24.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [01:27<07:06,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.293 | Train PPL:  26.931\n",
      "\t Val. Loss: 3.147 |  Val. PPL:  23.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [01:32<07:00,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.246 | Train PPL:  25.680\n",
      "\t Val. Loss: 3.100 |  Val. PPL:  22.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:37<06:55,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.199 | Train PPL:  24.519\n",
      "\t Val. Loss: 3.054 |  Val. PPL:  21.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:42<06:50,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.150 | Train PPL:  23.347\n",
      "\t Val. Loss: 3.018 |  Val. PPL:  20.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:47<06:44,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.105 | Train PPL:  22.320\n",
      "\t Val. Loss: 2.969 |  Val. PPL:  19.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:52<06:39,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.060 | Train PPL:  21.324\n",
      "\t Val. Loss: 2.910 |  Val. PPL:  18.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:57<06:35,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 3.014 | Train PPL:  20.360\n",
      "\t Val. Loss: 2.869 |  Val. PPL:  17.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [02:03<06:32,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.973 | Train PPL:  19.558\n",
      "\t Val. Loss: 2.831 |  Val. PPL:  16.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [02:08<06:27,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.934 | Train PPL:  18.801\n",
      "\t Val. Loss: 2.791 |  Val. PPL:  16.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [02:13<06:23,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.894 | Train PPL:  18.067\n",
      "\t Val. Loss: 2.738 |  Val. PPL:  15.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [02:18<06:18,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.854 | Train PPL:  17.359\n",
      "\t Val. Loss: 2.723 |  Val. PPL:  15.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [02:24<06:16,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.815 | Train PPL:  16.687\n",
      "\t Val. Loss: 2.689 |  Val. PPL:  14.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [02:29<06:10,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.778 | Train PPL:  16.080\n",
      "\t Val. Loss: 2.632 |  Val. PPL:  13.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [02:34<06:04,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.741 | Train PPL:  15.499\n",
      "\t Val. Loss: 2.595 |  Val. PPL:  13.397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [02:39<05:59,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.704 | Train PPL:  14.933\n",
      "\t Val. Loss: 2.561 |  Val. PPL:  12.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [02:44<05:52,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.668 | Train PPL:  14.416\n",
      "\t Val. Loss: 2.541 |  Val. PPL:  12.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [02:49<05:45,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.630 | Train PPL:  13.876\n",
      "\t Val. Loss: 2.506 |  Val. PPL:  12.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [02:55<05:39,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.596 | Train PPL:  13.412\n",
      "\t Val. Loss: 2.468 |  Val. PPL:  11.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [03:00<05:33,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.555 | Train PPL:  12.877\n",
      "\t Val. Loss: 2.430 |  Val. PPL:  11.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [03:05<05:27,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.518 | Train PPL:  12.409\n",
      "\t Val. Loss: 2.405 |  Val. PPL:  11.080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [03:10<05:22,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.479 | Train PPL:  11.928\n",
      "\t Val. Loss: 2.354 |  Val. PPL:  10.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [03:15<05:18,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.439 | Train PPL:  11.465\n",
      "\t Val. Loss: 2.333 |  Val. PPL:  10.310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [03:20<05:12,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.399 | Train PPL:  11.013\n",
      "\t Val. Loss: 2.275 |  Val. PPL:   9.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [03:25<05:07,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.361 | Train PPL:  10.602\n",
      "\t Val. Loss: 2.241 |  Val. PPL:   9.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [03:30<05:02,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.324 | Train PPL:  10.218\n",
      "\t Val. Loss: 2.223 |  Val. PPL:   9.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [03:36<04:57,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.285 | Train PPL:   9.825\n",
      "\t Val. Loss: 2.184 |  Val. PPL:   8.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [03:41<04:53,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.249 | Train PPL:   9.478\n",
      "\t Val. Loss: 2.158 |  Val. PPL:   8.650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [03:46<04:48,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.216 | Train PPL:   9.172\n",
      "\t Val. Loss: 2.123 |  Val. PPL:   8.356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [03:51<04:43,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.180 | Train PPL:   8.851\n",
      "\t Val. Loss: 2.101 |  Val. PPL:   8.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [03:56<04:37,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.153 | Train PPL:   8.612\n",
      "\t Val. Loss: 2.070 |  Val. PPL:   7.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [04:01<04:32,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.121 | Train PPL:   8.340\n",
      "\t Val. Loss: 2.054 |  Val. PPL:   7.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [04:06<04:27,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.095 | Train PPL:   8.126\n",
      "\t Val. Loss: 2.030 |  Val. PPL:   7.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [04:12<04:21,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.065 | Train PPL:   7.889\n",
      "\t Val. Loss: 2.015 |  Val. PPL:   7.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [04:17<04:16,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.039 | Train PPL:   7.680\n",
      "\t Val. Loss: 2.004 |  Val. PPL:   7.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [04:22<04:10,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 2.011 | Train PPL:   7.469\n",
      "\t Val. Loss: 1.987 |  Val. PPL:   7.291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [04:27<04:05,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 1.988 | Train PPL:   7.302\n",
      "\t Val. Loss: 1.962 |  Val. PPL:   7.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [04:32<04:00,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 1.968 | Train PPL:   7.155\n",
      "\t Val. Loss: 1.941 |  Val. PPL:   6.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [04:37<03:55,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 1.942 | Train PPL:   6.970\n",
      "\t Val. Loss: 1.939 |  Val. PPL:   6.950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [04:42<03:49,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 1.922 | Train PPL:   6.837\n",
      "\t Val. Loss: 1.924 |  Val. PPL:   6.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [04:47<03:55,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 1.966 | Test PPL:   7.140 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          iterator: BucketIterator,\n",
    "          optimizer: optim.Optimizer,\n",
    "          criterion: nn.Module,\n",
    "          clip: float):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for idx, batch in enumerate(iterator):\n",
    "\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output, enc_attention_scores, _ = model(src, trg)\n",
    "\n",
    "        output = output[:,:-1,:].reshape(-1, output.shape[-1])\n",
    "        trg = trg[:,1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module,\n",
    "             iterator: BucketIterator,\n",
    "             criterion: nn.Module):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for _, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output, attention_score, _ = model(src, trg) #turn off teacher forcing\n",
    "\n",
    "            output = output[:,:-1,:].reshape(-1, output.shape[-1])\n",
    "            trg = trg[:,1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "for epoch in tqdm(range(N_EPOCHS), total=N_EPOCHS):\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    if best_valid_loss < valid_loss:\n",
    "        break\n",
    "    else:\n",
    "        best_valid_loss = valid_loss\n",
    "\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
<<<<<<< HEAD
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
=======
    "\n"
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxyJad1WEbN8"
   },
   "source": [
    "# IV. Visualization\n",
    "<a id='4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_Eop7pGEbN8"
   },
   "source": [
    "## 1. Positional embedding visualization"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 16,
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
   "metadata": {
    "id": "QJKGr5JfEbN8",
    "scrolled": false
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Sequence Length')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(15, 9))\n",
    "cax = ax.matshow(model.encoder.embed_positions.weight.data.cpu().numpy(), aspect='auto',cmap=plt.cm.YlOrRd)\n",
    "fig.colorbar(cax)\n",
    "ax.set_title('Positional Embedding Matrix', fontsize=18)\n",
    "ax.set_xlabel('Embedding Dimension', fontsize=14)\n",
    "ax.set_ylabel('Sequence Length', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrLCVOWlEbN8"
   },
   "source": [
    "## 2. Attention visualization"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 26,
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
   "metadata": {
    "id": "azwmQfF-EbN8",
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (enc_embedding): Embedding(7853, 64, padding_idx=1)\n",
       "  (dec_embedding): Embedding(5893, 64, padding_idx=1)\n",
       "  (encoder): Encoder(\n",
       "    (embed_tokens): Embedding(7853, 64, padding_idx=1)\n",
       "    (embed_positions): SinusoidalPositionalEmbedding(512, 64)\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): ReLU()\n",
       "        (PositionWiseFeedForward): PositionWiseFeedForward(\n",
       "          (activation): ReLU()\n",
       "          (w_1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (w_2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): ReLU()\n",
       "        (PositionWiseFeedForward): PositionWiseFeedForward(\n",
       "          (activation): ReLU()\n",
       "          (w_1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (w_2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): ReLU()\n",
       "        (PositionWiseFeedForward): PositionWiseFeedForward(\n",
       "          (activation): ReLU()\n",
       "          (w_1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (w_2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embed_tokens): Embedding(5893, 64, padding_idx=1)\n",
       "    (embed_positions): SinusoidalPositionalEmbedding(512, 64)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiHeadAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (PositionWiseFeedForward): PositionWiseFeedForward(\n",
       "          (activation): ReLU()\n",
       "          (w_1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (w_2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiHeadAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (PositionWiseFeedForward): PositionWiseFeedForward(\n",
       "          (activation): ReLU()\n",
       "          (w_1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (w_2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiHeadAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (PositionWiseFeedForward): PositionWiseFeedForward(\n",
       "          (activation): ReLU()\n",
       "          (w_1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (w_2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prediction_head): Linear(in_features=64, out_features=5893, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
   "source": [
    "from attentionviz import head_view\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "train_iterator, _, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 27,
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
   "metadata": {
    "id": "tLCz7R73EbN8",
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: regex in /home/seonghaeom/anaconda3/lib/python3.9/site-packages (2022.3.15)\n"
     ]
    }
   ],
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
   "source": [
    "import sys\n",
    "if not 'attentionviz' in sys.path:\n",
    "  sys.path += ['attentionviz']\n",
    "!pip install regex\n",
    "\n",
    "def call_html():\n",
    "  import IPython\n",
    "  display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
    "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 30,
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
   "metadata": {
    "id": "RkV8XEM2EbN9",
    "scrolled": false
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  5.5084, -10.9349, -10.9549,  ...,  -7.3994,  -8.3655,  -9.3128],\n",
      "         [  7.2044,  -8.3388,  -8.3109,  ...,  -5.7551,  -7.5960,  -6.1984],\n",
      "         [  9.2868,  -7.4777,  -7.3325,  ...,  -7.3154,  -6.1012,  -6.1258],\n",
      "         ...,\n",
      "         [  6.3199,  -9.1294,  -9.1109,  ...,  -7.2875,  -6.6784,  -5.5130],\n",
      "         [  3.3209,  -6.7648,  -6.8213,  ...,  -8.5147,  -8.5964,  -8.8485],\n",
      "         [  5.6521,  -8.2180,  -8.1497,  ...,  -6.8960,  -7.0103,  -7.7220]]],\n",
      "       device='cuda:0')\n",
      "['<sos>', 'eine', 'junge', 'dame', 'macht', 'yoga', 'am', 'strand', '.', '<eos>'] ['<sos>', 'a', 'young', 'lady', 'doing', 'yoga', 'on', 'the', 'beach', '.', '<eos>']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
       "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <span style=\"user-select:none\">\n",
       "            Layer: <select id=\"layer\"></select>\n",
       "            Attention: <select id=\"filter\">\n",
       "              <option value=\"cross\">cross</option>\n",
       "              <option value=\"self\">self</option>\n",
       "            </select>\n",
       "            </span>\n",
       "        <div id='vis'></div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "window.params = {\"attention\": {\"self\": {\"attn\": [[[[0.08340398222208023, 0.07282684743404388, 0.07351970672607422, 0.06298965215682983, 0.12644191086292267, 0.23490197956562042, 0.12621617317199707, 0.07538433372974396, 0.07255440205335617, 0.07176109403371811], [0.08769069612026215, 0.09158334136009216, 0.09598814696073532, 0.08259570598602295, 0.12518788874149323, 0.19662848114967346, 0.1010599359869957, 0.07047711312770844, 0.0756915733218193, 0.0730971023440361], [0.08755158632993698, 0.10824534296989441, 0.1178748831152916, 0.09956350177526474, 0.12396099418401718, 0.17777977883815765, 0.08027642965316772, 0.06142406910657883, 0.07394693791866302, 0.06937648355960846], [0.08554612100124359, 0.11108395457267761, 0.12279265373945236, 0.10201075673103333, 0.12562867999076843, 0.18313124775886536, 0.07445844262838364, 0.05703886225819588, 0.07160787284374237, 0.06670144945383072], [0.08015763759613037, 0.08004632592201233, 0.0841158926486969, 0.06892690062522888, 0.13193565607070923, 0.2535772919654846, 0.10511571913957596, 0.06311153620481491, 0.06766452640295029, 0.06534848362207413], [0.07565753161907196, 0.07230417430400848, 0.07553009688854218, 0.06028992682695389, 0.1337893009185791, 0.2905634641647339, 0.11018303036689758, 0.05941098928451538, 0.062197115272283554, 0.06007438525557518], [0.07706212252378464, 0.05947372317314148, 0.058735769242048264, 0.0495154932141304, 0.12660014629364014, 0.27677035331726074, 0.1432553082704544, 0.0744607076048851, 0.06690850108861923, 0.0672178566455841], [0.06767475605010986, 0.05078219622373581, 0.05074078589677811, 0.04032508283853531, 0.1288597583770752, 0.34807097911834717, 0.14195409417152405, 0.061506543308496475, 0.055195532739162445, 0.05489020422101021], [0.07007819414138794, 0.053908880800008774, 0.0539579838514328, 0.04324946179986, 0.1292949616909027, 0.3319036364555359, 0.1401890367269516, 0.06320793181657791, 0.05734958127140999, 0.056860409677028656], [0.07073455303907394, 0.053713031113147736, 0.053499285131692886, 0.043380238115787506, 0.1288762390613556, 0.3244500458240509, 0.14193005859851837, 0.06545437127351761, 0.05900675430893898, 0.05895547196269035]], [[0.08041514456272125, 0.054074276238679886, 0.09191437065601349, 0.05601506680250168, 0.09822719544172287, 0.2388671636581421, 0.09600886702537537, 0.13255548477172852, 0.07964734733104706, 0.07227513939142227], [0.08315756171941757, 0.0750807374715805, 0.17545096576213837, 0.090819351375103, 0.10065794736146927, 0.1803259402513504, 0.06266634911298752, 0.09383203089237213, 0.07029232382774353, 0.06771676987409592], [0.06984050571918488, 0.08451487123966217, 0.38599056005477905, 0.1318713128566742, 0.08178482204675674, 0.11545353382825851, 0.026133965700864792, 0.03691861033439636, 0.03398207947611809, 0.033509694039821625], [0.06221946328878403, 0.07265134155750275, 0.4235241115093231, 0.14320062100887299, 0.09226445853710175, 0.12094609439373016, 0.021442890167236328, 0.021524731069803238, 0.020895618945360184, 0.02133062109351158], [0.06112723797559738, 0.033249352127313614, 0.06296870857477188, 0.05095026269555092, 0.16186745464801788, 0.36504852771759033, 0.10207174718379974, 0.07941519469022751, 0.038471952080726624, 0.04482961446046829], [0.05920165404677391, 0.029794881120324135, 0.0645681768655777, 0.04198642447590828, 0.13946829736232758, 0.4126273989677429, 0.0962408035993576, 0.08487191051244736, 0.03392725810408592, 0.03731318563222885], [0.06216645985841751, 0.029544219374656677, 0.03267373889684677, 0.029159344732761383, 0.10117948800325394, 0.30253535509109497, 0.14265283942222595, 0.1558048278093338, 0.07414320111274719, 0.07014050334692001], [0.06629025191068649, 0.0409591905772686, 0.06514500081539154, 0.031980808824300766, 0.06779733300209045, 0.25121259689331055, 0.09168386459350586, 0.2101995199918747, 0.09270438551902771, 0.08202707767486572], [0.06195421144366264, 0.037481870502233505, 0.05858105421066284, 0.03029509261250496, 0.06379891186952591, 0.23599153757095337, 0.08743326365947723, 0.2096291035413742, 0.11830978095531464, 0.09652522206306458], [0.06178963929414749, 0.03893819823861122, 0.0600723922252655, 0.03349347412586212, 0.07554757595062256, 0.24867698550224304, 0.08966364711523056, 0.19399327039718628, 0.10293684154748917, 0.09488796442747116]], [[0.06393411755561829, 0.03198593109846115, 0.04793186113238335, 0.07781073451042175, 0.12327685207128525, 0.2774721086025238, 0.10832013934850693, 0.10183478891849518, 0.08693412691354752, 0.08049933612346649], [0.06777957826852798, 0.050273653119802475, 0.11629557609558105, 0.13578851521015167, 0.1167411357164383, 0.22118692100048065, 0.060453642159700394, 0.07730179280042648, 0.08105272054672241, 0.07312647998332977], [0.05903620272874832, 0.06317077577114105, 0.20690757036209106, 0.1897030919790268, 0.11071193218231201, 0.18145418167114258, 0.03343909978866577, 0.047507140785455704, 0.05612405762076378, 0.05194595083594322], [0.05300656706094742, 0.062409017235040665, 0.21222804486751556, 0.19710983335971832, 0.12254829704761505, 0.1975376307964325, 0.03072163090109825, 0.038117147982120514, 0.04387637600302696, 0.04244547709822655], [0.04332186281681061, 0.030150890350341797, 0.053219642490148544, 0.09105215966701508, 0.17859259247779846, 0.40178096294403076, 0.07772417366504669, 0.04621311277151108, 0.03808025270700455, 0.039864398539066315], [0.03592865914106369, 0.02591659128665924, 0.042987242341041565, 0.0798945277929306, 0.1950739473104477, 0.44550085067749023, 0.07732319086790085, 0.039211515337228775, 0.026830989867448807, 0.03133244812488556], [0.05579661950469017, 0.023786891251802444, 0.027500515803694725, 0.054647549986839294, 0.12902748584747314, 0.3090631365776062, 0.142581045627594, 0.10857313126325607, 0.0742153599858284, 0.07480819523334503], [0.05882998928427696, 0.022402437403798103, 0.03486908972263336, 0.06217518076300621, 0.10096929967403412, 0.2603641450405121, 0.116915263235569, 0.15686051547527313, 0.09169786423444748, 0.09491618722677231], [0.05714230611920357, 0.016404645517468452, 0.03399167209863663, 0.06094660982489586, 0.07714483141899109, 0.26229047775268555, 0.09426082670688629, 0.15815691649913788, 0.13347972929477692, 0.10618200898170471], [0.05926431715488434, 0.018712151795625687, 0.034274667501449585, 0.0608307309448719, 0.08231323212385178, 0.2477022111415863, 0.10355684906244278, 0.16404858231544495, 0.12256335467100143, 0.10673387348651886]], [[0.14306730031967163, 0.12640832364559174, 0.0698842778801918, 0.05193677917122841, 0.10318542271852493, 0.11792989820241928, 0.15678034722805023, 0.06431303173303604, 0.08944480121135712, 0.07704975455999374], [0.15040163695812225, 0.19695214927196503, 0.1119091808795929, 0.07387187331914902, 0.09805946797132492, 0.07856310904026031, 0.10747826844453812, 0.047324247658252716, 0.0713953748345375, 0.06404461711645126], [0.1507405787706375, 0.25818905234336853, 0.14251601696014404, 0.0833120346069336, 0.09299742430448532, 0.059717193245887756, 0.07846725732088089, 0.03221651166677475, 0.05331653356552124, 0.04852741211652756], [0.14955967664718628, 0.2725876569747925, 0.14521844685077667, 0.08357007801532745, 0.09448669105768204, 0.05844057351350784, 0.0741899386048317, 0.028750808909535408, 0.0488092340528965, 0.04438687115907669], [0.152320995926857, 0.15505735576152802, 0.07785926014184952, 0.052256375551223755, 0.11580462008714676, 0.12149128317832947, 0.1448819786310196, 0.047584038227796555, 0.07035315036773682, 0.062390975654125214], [0.1478733867406845, 0.1376112997531891, 0.06436492502689362, 0.045083679258823395, 0.12877565622329712, 0.15494947135448456, 0.15640796720981598, 0.04355823993682861, 0.06611263751983643, 0.055262718349695206], [0.1329749971628189, 0.09000198543071747, 0.04729825258255005, 0.03678567707538605, 0.09733522683382034, 0.1386074423789978, 0.1977728307247162, 0.07537941634654999, 0.09843872487545013, 0.08540544658899307], [0.16513626277446747, 0.11302896589040756, 0.04487892612814903, 0.02669597789645195, 0.071696437895298, 0.09082202613353729, 0.22922499477863312, 0.06646808981895447, 0.10274302214384079, 0.0893053412437439], [0.17326882481575012, 0.12861204147338867, 0.05030310899019241, 0.028653739020228386, 0.06918861716985703, 0.08114262670278549, 0.21628110110759735, 0.06277982890605927, 0.1022460013628006, 0.08752412348985672], [0.1791529357433319, 0.13863728940486908, 0.05470849201083183, 0.028587451204657555, 0.061190519481897354, 0.06534913927316666, 0.210028737783432, 0.06419289857149124, 0.10315796732902527, 0.09499460458755493]]], [[[0.11224665492773056, 0.14524343609809875, 0.1169806495308876, 0.10879140347242355, 0.08429111540317535, 0.06441258639097214, 0.052745521068573, 0.06717749685049057, 0.1288483440876007, 0.11926277726888657], [0.11603424698114395, 0.19364473223686218, 0.12594592571258545, 0.1090337336063385, 0.06566862761974335, 0.038477856665849686, 0.02586587890982628, 0.04183065891265869, 0.15261857211589813, 0.13087981939315796], [0.11554040759801865, 0.21367816627025604, 0.1274632215499878, 0.10719714313745499, 0.05831247940659523, 0.03068767674267292, 0.019052112475037575, 0.033931270241737366, 0.160598486661911, 0.13353899121284485], [0.1153818890452385, 0.21660909056663513, 0.12761443853378296, 0.10687533766031265, 0.057283684611320496, 0.02968277968466282, 0.018213413655757904, 0.032896459102630615, 0.1616390198469162, 0.1338038146495819], [0.11499729007482529, 0.16764740645885468, 0.12213172763586044, 0.10982850193977356, 0.07561630010604858, 0.0510115846991539, 0.038085777312517166, 0.05425284057855606, 0.1407400220632553, 0.1256885528564453], [0.11076537519693375, 0.13711349666118622, 0.11460445821285248, 0.10791836678981781, 0.08736301213502884, 0.06991193443536758, 0.05925252288579941, 0.07239256799221039, 0.12419021874666214, 0.1164880245923996], [0.07216452062129974, 0.05083995312452316, 0.06827178597450256, 0.07535887509584427, 0.10661256313323975, 0.15376576781272888, 0.2016458958387375, 0.1451408863067627, 0.059785205870866776, 0.06641459465026855], [0.07169599831104279, 0.05024794489145279, 0.06777821481227875, 0.0749252587556839, 0.10654687881469727, 0.1545228511095047, 0.20344135165214539, 0.14572152495384216, 0.059224843978881836, 0.06589510291814804], [0.09794627130031586, 0.09497033059597015, 0.0975014716386795, 0.09835546463727951, 0.10141932219266891, 0.10477136820554733, 0.10729363560676575, 0.10421999543905258, 0.09630977362394333, 0.09721231460571289], [0.09718169271945953, 0.09317392110824585, 0.09656492620706558, 0.09772052615880966, 0.10189498960971832, 0.10650654137134552, 0.11002515256404877, 0.10575021803379059, 0.09498383104801178, 0.09619809687137604]], [[0.12180837243795395, 0.14391878247261047, 0.15491466224193573, 0.13863177597522736, 0.09368086606264114, 0.07564259320497513, 0.03196040913462639, 0.04061925783753395, 0.10488301515579224, 0.09394022077322006], [0.12726172804832458, 0.19327767193317413, 0.2323707491159439, 0.17599926888942719, 0.06600087881088257, 0.03863999620079994, 0.004468466155230999, 0.008144758641719818, 0.08746200054883957, 0.06637448072433472], [0.12563607096672058, 0.20162172615528107, 0.24837270379066467, 0.18132494390010834, 0.05972710996866226, 0.032576315104961395, 0.0028327093459665775, 0.0055893780663609505, 0.08218363672494888, 0.06013542413711548], [0.12447778880596161, 0.20575477182865143, 0.2567821145057678, 0.1838330328464508, 0.05650797113776207, 0.029679113999009132, 0.002216203371062875, 0.004562296438962221, 0.07928846776485443, 0.05689826235175133], [0.12806940078735352, 0.17592239379882812, 0.2023649662733078, 0.16383019089698792, 0.07773397117853165, 0.05174810811877251, 0.010044554248452187, 0.015850970521569252, 0.09632740914821625, 0.07810800522565842], [0.12406770884990692, 0.15137183666229248, 0.1652524471282959, 0.14476200938224792, 0.09073378890752792, 0.07031416893005371, 0.02517678216099739, 0.033506713807582855, 0.10379555821418762, 0.09101898968219757], [0.05931263789534569, 0.049253568053245544, 0.04537856951355934, 0.05135756731033325, 0.07947299629449844, 0.1008673906326294, 0.26340416073799133, 0.20166629552841187, 0.07006685435771942, 0.0792199894785881], [0.049805283546447754, 0.03964599594473839, 0.035853318870067596, 0.04173347353935242, 0.07131317257881165, 0.09554727375507355, 0.3103376030921936, 0.22360442578792572, 0.06111079081892967, 0.07104864716529846], [0.08548280596733093, 0.07954169809818268, 0.0770624428987503, 0.08083910495042801, 0.09571268409490585, 0.10496771335601807, 0.1522640734910965, 0.13729621469974518, 0.09119515866041183, 0.09563805907964706], [0.08700238913297653, 0.08152637630701065, 0.07923024147748947, 0.08272753655910492, 0.0963510274887085, 0.10472317039966583, 0.14649692177772522, 0.13343559205532074, 0.09223037213087082, 0.09627631306648254]], [[0.09516891092061996, 0.13855190575122833, 0.15229904651641846, 0.1590607464313507, 0.09764774143695831, 0.0861331969499588, 0.054327722638845444, 0.06107551231980324, 0.0795268565416336, 0.07620827108621597], [0.08385613560676575, 0.16513659060001373, 0.19586043059825897, 0.2118842601776123, 0.08807133883237839, 0.0702233836054802, 0.030542690306901932, 0.03770461305975914, 0.06060192734003067, 0.05611862242221832], [0.07973333448171616, 0.17149464786052704, 0.207962766289711, 0.22735027968883514, 0.08444039523601532, 0.06536613404750824, 0.025492139160633087, 0.03232748433947563, 0.05521218851208687, 0.0506206713616848], [0.0643567219376564, 0.1879970282316208, 0.24624836444854736, 0.2790060341358185, 0.06982716172933578, 0.04879365488886833, 0.013053196482360363, 0.018196184188127518, 0.03846093267202377, 0.034060727804899216], [0.09119170904159546, 0.15023338794708252, 0.1703796088695526, 0.1804932802915573, 0.09431154280900955, 0.07982619851827621, 0.043276406824588776, 0.05056481063365936, 0.07183898240327835, 0.06788407266139984], [0.09121035784482956, 0.15007565915584564, 0.17014266550540924, 0.1802482008934021, 0.09446017444133759, 0.07997950166463852, 0.04340514540672302, 0.050674159079790115, 0.07187404483556747, 0.06793013960123062], [0.09992127865552902, 0.09772874414920807, 0.09719657897949219, 0.09694269299507141, 0.09975717216730118, 0.10050832480192184, 0.10323944687843323, 0.10255197435617447, 0.10095307230949402, 0.10120067000389099], [0.09980060160160065, 0.1115475594997406, 0.11472064256668091, 0.11621978133916855, 0.10068129748106003, 0.0970110073685646, 0.08454661071300507, 0.08752992749214172, 0.09456786513328552, 0.09337478131055832], [0.09930238127708435, 0.1178789734840393, 0.12310060113668442, 0.12554135918617249, 0.10032261162996292, 0.09474582225084305, 0.07680162042379379, 0.08104941248893738, 0.09151177853345871, 0.08974544703960419], [0.09967783093452454, 0.11411971598863602, 0.11809428781270981, 0.11992868036031723, 0.1004239022731781, 0.09599603712558746, 0.08135464787483215, 0.08489800244569778, 0.09346725791692734, 0.09203963726758957]], [[0.09865260869264603, 0.10021089017391205, 0.100003682076931, 0.09884470701217651, 0.10079465061426163, 0.10201884061098099, 0.10154934227466583, 0.10193542391061783, 0.0975286066532135, 0.09846130013465881], [0.11003607511520386, 0.09530781954526901, 0.09654353559017181, 0.10457602143287659, 0.091746985912323, 0.0843280553817749, 0.09195691347122192, 0.08869307488203049, 0.12235166132450104, 0.11445975303649902], [0.11231433600187302, 0.0941372886300087, 0.09565342962741852, 0.10559434443712234, 0.08979679644107819, 0.08090359717607498, 0.08986616879701614, 0.08596999943256378, 0.12794694304466248, 0.11781706660985947], [0.10397258400917053, 0.09823939949274063, 0.0987318754196167, 0.10183786600828171, 0.09683118760585785, 0.09371236711740494, 0.09700056910514832, 0.09562569111585617, 0.10841269046068192, 0.10563576966524124], [0.09239833801984787, 0.10234663635492325, 0.10133583098649979, 0.0953957810997963, 0.10535377264022827, 0.11226199567317963, 0.10619046539068222, 0.10893373191356659, 0.08568693697452545, 0.09009655565023422], [0.08637093007564545, 0.10405507683753967, 0.10226073116064072, 0.09186995774507523, 0.10952232778072357, 0.12260545045137405, 0.11024162173271179, 0.11550531536340714, 0.07527414709329605, 0.08229435980319977], [0.08168420195579529, 0.10529810190200806, 0.10289280861616135, 0.08916687965393066, 0.11272018402814865, 0.13108690083026886, 0.11285366863012314, 0.12028397619724274, 0.06771588325500488, 0.07629736512899399], [0.0909973680973053, 0.1031838059425354, 0.10203768312931061, 0.09513788670301437, 0.10663231462240219, 0.1148117408156395, 0.10647488385438919, 0.10989725589752197, 0.08292005211114883, 0.08790702372789383], [0.09320658445358276, 0.10192570835351944, 0.10099530220031738, 0.09562733769416809, 0.10465623438358307, 0.11082492023706436, 0.10589846968650818, 0.10827475041151047, 0.08727394789457321, 0.09131677448749542], [0.09648360311985016, 0.10087351500988007, 0.10036963224411011, 0.09750489145517349, 0.10230673849582672, 0.10544803738594055, 0.10341852903366089, 0.10455480962991714, 0.09338948875665665, 0.09565079212188721]]], [[[0.08630262315273285, 0.07072228193283081, 0.10167510062456131, 0.09151793271303177, 0.061795394867658615, 0.050836674869060516, 0.16105332970619202, 0.16318953037261963, 0.09929026663303375, 0.11361680179834366], [0.1002030074596405, 0.12997648119926453, 0.08103320747613907, 0.0929756835103035, 0.1546092927455902, 0.1992364078760147, 0.04454931989312172, 0.04379364103078842, 0.08353019505739212, 0.07009270787239075], [0.08406674861907959, 0.13919402658939362, 0.05569953843951225, 0.07266044616699219, 0.19475845992565155, 0.31839197874069214, 0.017420679330825806, 0.016847368329763412, 0.05898354575037956, 0.04197721183300018], [0.09598807990550995, 0.13571332395076752, 0.07239572703838348, 0.0868183821439743, 0.1708017736673355, 0.23931726813316345, 0.03252461180090904, 0.03178085386753082, 0.07515663653612137, 0.059503376483917236], [0.08014271408319473, 0.061562392860651016, 0.09964898228645325, 0.08663405478000641, 0.05142224580049515, 0.03969525918364525, 0.18299299478530884, 0.1862165331840515, 0.09641389548778534, 0.11527100205421448], [0.07816873490810394, 0.05887368321418762, 0.09873282164335251, 0.08495312929153442, 0.04857552424073219, 0.036796845495700836, 0.18972288072109222, 0.19332142174243927, 0.0953475832939148, 0.1155073344707489], [0.066834956407547, 0.045150499790906906, 0.0920833945274353, 0.07484620809555054, 0.03473753482103348, 0.023695800453424454, 0.22706599533557892, 0.2330230474472046, 0.08796151727437973, 0.1146010160446167], [0.08454102277755737, 0.06782980263233185, 0.10120067745447159, 0.09005682170391083, 0.05852356180548668, 0.047216810286045074, 0.16767443716526031, 0.17010469734668732, 0.09854379296302795, 0.11430837213993073], [0.05540953204035759, 0.03363070264458656, 0.08349767327308655, 0.06409004330635071, 0.02400837652385235, 0.014730432070791721, 0.2635464668273926, 0.27236104011535645, 0.07859166711568832, 0.11013402789831161], [0.058594729751348495, 0.03666013851761818, 0.0860925242304802, 0.06716778129339218, 0.02672501653432846, 0.016895286738872528, 0.2534155249595642, 0.2613688111305237, 0.0813739225268364, 0.11170622706413269]], [[0.09768061339855194, 0.0817287415266037, 0.0496881864964962, 0.06369788944721222, 0.08305369317531586, 0.06091101095080376, 0.1456737518310547, 0.12152636051177979, 0.14237020909786224, 0.1536695957183838], [0.10076750814914703, 0.09688672423362732, 0.0868777334690094, 0.091643325984478, 0.09722888469696045, 0.09074386209249496, 0.10982652008533478, 0.10543537139892578, 0.10937196761369705, 0.11121814697980881], [0.10078565031290054, 0.09299303591251373, 0.07433001697063446, 0.08299582451581955, 0.09366666525602341, 0.0813404843211174, 0.12037746608257294, 0.11076579242944717, 0.11929035186767578, 0.12345470488071442], [0.09710636734962463, 0.10428827255964279, 0.1273418515920639, 0.11508171260356903, 0.10361078381538391, 0.11715894937515259, 0.08252579718828201, 0.08861098438501358, 0.08339747041463852, 0.08087783306837082], [0.09943672269582748, 0.10097913444042206, 0.1049368679523468, 0.10315455496311188, 0.10064727813005447, 0.1032051295042038, 0.09666746109724045, 0.09816009551286697, 0.09668292850255966, 0.09612978249788284], [0.09860233217477798, 0.10239182412624359, 0.11325634270906448, 0.10791391879320145, 0.10186336189508438, 0.10859493166208267, 0.09117045253515244, 0.09469952434301376, 0.09144914895296097, 0.09005811810493469], [0.10066376626491547, 0.09356733411550522, 0.07632797211408615, 0.08453825116157532, 0.09421892464160919, 0.08305074274539948, 0.11865498125553131, 0.11026514321565628, 0.11748893558979034, 0.12122388929128647], [0.10070263594388962, 0.09481853246688843, 0.08018528670072556, 0.08723714202642441, 0.09538048505783081, 0.0859917625784874, 0.11534061282873154, 0.10858778655529022, 0.11438773572444916, 0.11736803501844406], [0.09531351923942566, 0.07656203210353851, 0.041546694934368134, 0.056408997625112534, 0.07810787111520767, 0.053411815315485, 0.1559027135372162, 0.1248892992734909, 0.15147718787193298, 0.166379913687706], [0.09438395500183105, 0.07474599778652191, 0.03899013251066208, 0.05399426072835922, 0.0763595774769783, 0.05095042660832405, 0.159371480345726, 0.12584874033927917, 0.1545592099428177, 0.17079627513885498]], [[0.1130090057849884, 0.16178129613399506, 0.18101654946804047, 0.1286383420228958, 0.11293869465589523, 0.12055173516273499, 0.03303517773747444, 0.029279520735144615, 0.061729662120342255, 0.05802004039287567], [0.0550059974193573, 0.2687399089336395, 0.4436027705669403, 0.0972927063703537, 0.05490320920944214, 0.0734553337097168, 0.0002338985650567338, 0.00013662986748386174, 0.003767170710489154, 0.002862335415557027], [0.03394179791212082, 0.27549073100090027, 0.533123791217804, 0.07212530076503754, 0.033883851021528244, 0.04972057044506073, 2.5330802600365132e-05, 1.2477756172302179e-05, 0.000988258165307343, 0.0006878097774460912], [0.055036354809999466, 0.2687531113624573, 0.4433462619781494, 0.09736358374357224, 0.05496693402528763, 0.07351615279912949, 0.00023500926909036934, 0.00013738895358983427, 0.0037759020924568176, 0.0028693077620118856], [0.11290912330150604, 0.16797727346420288, 0.19076602160930634, 0.12999700009822845, 0.11264967173337936, 0.12131939083337784, 0.028458384796977043, 0.024807658046483994, 0.057473838329315186, 0.0536416731774807], [0.11283266544342041, 0.14797520637512207, 0.16153089702129364, 0.12412188947200775, 0.1125764474272728, 0.11849088966846466, 0.04382241889834404, 0.03985295072197914, 0.07103662192821503, 0.06776002049446106], [0.002692214213311672, 0.0006524466443806887, 0.0004171781474724412, 0.0016165050910785794, 0.00269507709890604, 0.0020786316599696875, 0.3527621626853943, 0.5698605179786682, 0.029509296640753746, 0.03771587461233139], [0.0026282358448952436, 0.0006328432937152684, 0.0004037624748889357, 0.0015750289894640446, 0.0026321839541196823, 0.0020274154376238585, 0.3525964617729187, 0.5710770487785339, 0.029140381142497063, 0.03728657215833664], [0.01066326443105936, 0.003894234076142311, 0.0028299966361373663, 0.007428077515214682, 0.01067153736948967, 0.008864794857800007, 0.34351015090942383, 0.4837314784526825, 0.05861271172761917, 0.06979380548000336], [0.008218653500080109, 0.002771418308839202, 0.00196392391808331, 0.0055633606389164925, 0.008225757628679276, 0.0067338463850319386, 0.348382830619812, 0.504036545753479, 0.05169335752725601, 0.06241030991077423]], [[0.10085293650627136, 0.08941294997930527, 0.08873658627271652, 0.09310762584209442, 0.08244171738624573, 0.07194554060697556, 0.11711112409830093, 0.12237493693828583, 0.11483597755432129, 0.11918064951896667], [0.0858789011836052, 0.1164378970861435, 0.11854686588048935, 0.10498742759227753, 0.1429227590560913, 0.201790913939476, 0.05878513678908348, 0.05255044251680374, 0.061828769743442535, 0.056270916014909744], [0.08090654760599136, 0.11747221648693085, 0.12002145498991013, 0.10346753895282745, 0.15080764889717102, 0.22985754907131195, 0.05083458870649338, 0.04431210458278656, 0.05410584434866905, 0.048214513808488846], [0.06691929697990417, 0.11507808417081833, 0.11891043186187744, 0.09577427059412003, 0.1658986210823059, 0.306591659784317, 0.034089088439941406, 0.02793201245367527, 0.03727979585528374, 0.031526755541563034], [0.09480728209018707, 0.1106506958603859, 0.11169490218162537, 0.1050313264131546, 0.12272708117961884, 0.14617420732975006, 0.07822370529174805, 0.07392323762178421, 0.08025356382131577, 0.07651395350694656], [0.08615967631340027, 0.11630656570196152, 0.11848220974206924, 0.10512109100818634, 0.14234238862991333, 0.19992020726203918, 0.05933695286512375, 0.05316473916172981, 0.062341075390577316, 0.056825023144483566], [0.09870470315217972, 0.07698258757591248, 0.07587381452322006, 0.08378468453884125, 0.0651325136423111, 0.049153465777635574, 0.13449840247631073, 0.14740391075611115, 0.1290740966796875, 0.13939179480075836], [0.10064909607172012, 0.08706643432378769, 0.08633560687303543, 0.0914841741323471, 0.0789436474442482, 0.06696169823408127, 0.12055449932813644, 0.12718188762664795, 0.11770656704902649, 0.12311633676290512], [0.09148556739091873, 0.05954617261886597, 0.058015063405036926, 0.06886714696884155, 0.044566620141267776, 0.027394020929932594, 0.15602251887321472, 0.18266795575618744, 0.14539693295955658, 0.16603799164295197], [0.08803092688322067, 0.053740084171295166, 0.05215298384428024, 0.06351400911808014, 0.03851524367928505, 0.022014157846570015, 0.16258475184440613, 0.19488339126110077, 0.14992620050907135, 0.17463822662830353]]]], \"left_text\": [\"<sos>\", \"eine\", \"junge\", \"dame\", \"macht\", \"yoga\", \"am\", \"strand\", \".\", \"<eos>\"], \"right_text\": [\"<sos>\", \"eine\", \"junge\", \"dame\", \"macht\", \"yoga\", \"am\", \"strand\", \".\", \"<eos>\"]}, \"cross\": {\"attn\": [[[[0.011524396948516369, 0.7351775765419006, 0.10997582226991653, 0.054771505296230316, 0.037242624908685684, 0.034273743629455566, 0.00565502792596817, 0.0019436749862506986, 0.004775868728756905, 0.004659762140363455], [0.016334641724824905, 0.683723509311676, 0.11616259068250656, 0.06390278786420822, 0.047616999596357346, 0.043912068009376526, 0.00911562517285347, 0.003573385067284107, 0.007903925143182278, 0.007754432037472725], [0.0026374943554401398, 0.886052668094635, 0.05984150618314743, 0.022854270413517952, 0.013710781000554562, 0.012110359966754913, 0.0010004471987485886, 0.00022676109801977873, 0.0007955729379318655, 0.0007700739079155028], [0.03612387925386429, 0.476249098777771, 0.13964776694774628, 0.10081053525209427, 0.0804205909371376, 0.08240292966365814, 0.02522149682044983, 0.014165684580802917, 0.022674672305583954, 0.022283410653471947], [0.04226922616362572, 0.40445956587791443, 0.12363187968730927, 0.10733034461736679, 0.09347192943096161, 0.10371438413858414, 0.035900164395570755, 0.024314505979418755, 0.03269335627555847, 0.032214581966400146], [0.07266493886709213, 0.2182731032371521, 0.13225308060646057, 0.12169196456670761, 0.10644558072090149, 0.11470628529787064, 0.06327289342880249, 0.05175086110830307, 0.05981516093015671, 0.059126175940036774], [0.07082859426736832, 0.22322463989257812, 0.12752500176429749, 0.11961207538843155, 0.10695365816354752, 0.11600024998188019, 0.06362186372280121, 0.052528418600559235, 0.06017514318227768, 0.059530314058065414], [0.10443996638059616, 0.05427280068397522, 0.07402089983224869, 0.0849250853061676, 0.08856707811355591, 0.09264688938856125, 0.11778976768255234, 0.14256145060062408, 0.12028023600578308, 0.12049584835767746], [0.09331148117780685, 0.14850880205631256, 0.1372804045677185, 0.12126994878053665, 0.10396849364042282, 0.10527573525905609, 0.07687167823314667, 0.06575260311365128, 0.07422977685928345, 0.07353110611438751], [0.10597027838230133, 0.09824898093938828, 0.11624803394079208, 0.1093621775507927, 0.09938172250986099, 0.09904942661523819, 0.09442905336618423, 0.09073343127965927, 0.0935131162405014, 0.09306379407644272], [0.1009916290640831, 0.12077230960130692, 0.13329239189624786, 0.1199532300233841, 0.10204068571329117, 0.10340174287557602, 0.08328286558389664, 0.07486138492822647, 0.08108289539813995, 0.08032085001468658]], [[0.0966724380850792, 0.10308055579662323, 0.08370575308799744, 0.061842069029808044, 0.11277017742395401, 0.14947083592414856, 0.11826542019844055, 0.09708584100008011, 0.08949477970600128, 0.08761215955018997], [0.08734031766653061, 0.12356364727020264, 0.12547793984413147, 0.1033998429775238, 0.10035663098096848, 0.1378084421157837, 0.09803390502929688, 0.08094453066587448, 0.07183006405830383, 0.07124467939138412], [0.09065864235162735, 0.11480948328971863, 0.09842681139707565, 0.06904914230108261, 0.11014556884765625, 0.16425968706607819, 0.11382213234901428, 0.08736018091440201, 0.07654086500406265, 0.07492751628160477], [0.08479157835245132, 0.12357045710086823, 0.10476148128509521, 0.06722625344991684, 0.11010327190160751, 0.18772609531879425, 0.1120157241821289, 0.07915479689836502, 0.06616729497909546, 0.06448301672935486], [0.1036263033747673, 0.08232701569795609, 0.05751796066761017, 0.04199067875742912, 0.11684825271368027, 0.13721822202205658, 0.12995804846286774, 0.11274471879005432, 0.11035823076963425, 0.10741052031517029], [0.11403948813676834, 0.04183686152100563, 0.02769225277006626, 0.02967034839093685, 0.09565001726150513, 0.05839841812849045, 0.11540070921182632, 0.14814311265945435, 0.18566930294036865, 0.1834995001554489], [0.11444485932588577, 0.04420037195086479, 0.030250100418925285, 0.032936498522758484, 0.09612186998128891, 0.05923411622643471, 0.11403261870145798, 0.1461694836616516, 0.18220722675323486, 0.18040283024311066], [0.11266142129898071, 0.03277657553553581, 0.02722758799791336, 0.04500763118267059, 0.07448981702327728, 0.028643811121582985, 0.08624881505966187, 0.1511298269033432, 0.21914470195770264, 0.22266976535320282], [0.1115560233592987, 0.028304770588874817, 0.019903652369976044, 0.028419455513358116, 0.07706832885742188, 0.0315602608025074, 0.09482631087303162, 0.1562894880771637, 0.22565172612667084, 0.22641997039318085], [0.11454257369041443, 0.03903311863541603, 0.031085340306162834, 0.044006187468767166, 0.08315931260585785, 0.038977526128292084, 0.09632667899131775, 0.14862239360809326, 0.2013760656118393, 0.20287074148654938], [0.11362697929143906, 0.03481770679354668, 0.02350030094385147, 0.02853616699576378, 0.08726435154676437, 0.044296834617853165, 0.10631988197565079, 0.15290845930576324, 0.20492203533649445, 0.20380732417106628]], [[0.15080378949642181, 0.14665399491786957, 0.055286429822444916, 0.04901444911956787, 0.04890673607587814, 0.03233563154935837, 0.15282686054706573, 0.07169697433710098, 0.14956192672252655, 0.1429131180047989], [0.058354321867227554, 0.05876968055963516, 0.10870257019996643, 0.1334986388683319, 0.16776049137115479, 0.21164032816886902, 0.057708725333213806, 0.086964912712574, 0.057414207607507706, 0.05918610468506813], [0.03991285711526871, 0.0374564602971077, 0.020260727033019066, 0.048095427453517914, 0.34485751390457153, 0.3210347294807434, 0.05964313820004463, 0.038688961416482925, 0.045241829007864, 0.044808365404605865], [0.001037727459333837, 0.000670954177621752, 4.499084025155753e-05, 0.000792697595898062, 0.537726879119873, 0.4477616250514984, 0.00639201607555151, 0.0012742250692099333, 0.0022158357314765453, 0.0020830794237554073], [0.013403769582509995, 0.008834787644445896, 0.0004425822990015149, 0.003653105115517974, 0.5035519003868103, 0.3431265950202942, 0.06482204794883728, 0.010597280226647854, 0.026951970532536507, 0.024615976959466934], [0.07780568301677704, 0.054641202092170715, 0.002818012610077858, 0.009416701272130013, 0.21178767085075378, 0.1140715703368187, 0.24286732077598572, 0.036725711077451706, 0.13160976767539978, 0.11825641989707947], [0.13331721723079681, 0.10750671476125717, 0.00989624485373497, 0.015445650555193424, 0.06684421747922897, 0.03428282216191292, 0.24558913707733154, 0.04925714433193207, 0.17705008387565613, 0.1608106642961502], [0.1523076295852661, 0.14261892437934875, 0.08753804862499237, 0.04764923080801964, 0.014342826791107655, 0.01125896442681551, 0.13917654752731323, 0.1000758558511734, 0.1551354080438614, 0.1498965173959732], [0.1469404697418213, 0.11995885521173477, 0.01126888208091259, 0.014518962241709232, 0.0464923158288002, 0.021837707608938217, 0.24083630740642548, 0.04652304947376251, 0.1844489425420761, 0.16717442870140076], [0.16963304579257965, 0.16415542364120483, 0.052489250898361206, 0.036095451563596725, 0.024746984243392944, 0.014171147719025612, 0.15764062106609344, 0.06400225311517715, 0.16303378343582153, 0.15403203666210175], [0.1771119236946106, 0.1704365760087967, 0.020298829302191734, 0.0182579904794693, 0.03005724586546421, 0.012472462840378284, 0.19489851593971252, 0.038746658712625504, 0.17677293717861176, 0.16094686090946198]], [[0.008800332434475422, 0.05155274644494057, 0.40732938051223755, 0.5170748233795166, 0.004174681380391121, 0.0028189432341605425, 0.0007012549904175103, 0.0018658590270206332, 0.00256612547673285, 0.0031158924102783203], [0.00020720763131976128, 0.004323768429458141, 0.23654943704605103, 0.7587227821350098, 3.411827128729783e-05, 2.4342036340385675e-05, 7.904570338723715e-06, 6.19048805674538e-05, 2.86644517473178e-05, 3.9918704715091735e-05], [0.00013600627426058054, 0.003903328673914075, 0.2235598862171173, 0.7722866535186768, 3.895504414686002e-05, 2.7575566491577774e-05, 3.1315869364334503e-06, 1.3472519640345126e-05, 1.3012888302910142e-05, 1.797270670067519e-05], [0.005381457507610321, 0.003228084882721305, 0.003966980148106813, 0.0067125544883310795, 0.5720662474632263, 0.39932069182395935, 0.0020043442491441965, 0.0001972813333850354, 0.0032716591376811266, 0.0038505876436829567], [0.013378217816352844, 0.010723630897700787, 0.0016733140219002962, 0.0030667553655803204, 0.3532106280326843, 0.5619450807571411, 0.035038094967603683, 0.0012990909162908792, 0.010908140800893307, 0.008757026866078377], [0.03580854460597038, 0.010060461238026619, 0.0008422550745308399, 0.0006861002766527236, 0.11578008532524109, 0.16603131592273712, 0.5285272598266602, 0.016794677823781967, 0.07082340121269226, 0.05464591830968857], [0.045576244592666626, 0.03456757590174675, 0.0040559615008533, 0.003831976791843772, 0.016015298664569855, 0.029642358422279358, 0.7005741596221924, 0.04948467016220093, 0.06783116608858109, 0.04842056334018707], [0.0725087821483612, 0.08036642521619797, 0.017273416742682457, 0.015385124832391739, 0.013154243119060993, 0.023691115900874138, 0.4376766085624695, 0.16883257031440735, 0.09791000187397003, 0.07320168614387512], [0.05639934539794922, 0.010886501520872116, 0.0015659520868211985, 0.0005902118282392621, 0.059028591960668564, 0.055365171283483505, 0.4882943630218506, 0.045785967260599136, 0.15063688158988953, 0.13144704699516296], [0.09312140941619873, 0.029505500569939613, 0.014753369614481926, 0.006794010754674673, 0.06873393058776855, 0.05018771067261696, 0.31729766726493835, 0.07249921560287476, 0.17236074805259705, 0.17474648356437683], [0.03908756002783775, 0.0034949551336467266, 0.0009512598044238985, 0.00028761508292518556, 0.035887956619262695, 0.022161858156323433, 0.518135666847229, 0.052140332758426666, 0.16073447465896606, 0.16711826622486115]]], [[[0.04339605197310448, 0.14036434888839722, 0.16288334131240845, 0.35567107796669006, 0.05801289901137352, 0.110103078186512, 0.03371099755167961, 0.04098159819841385, 0.027806997299194336, 0.02706955373287201], [0.021195905283093452, 0.12624549865722656, 0.15817420184612274, 0.5189996361732483, 0.0329839289188385, 0.0873841941356659, 0.014444708824157715, 0.019443953409790993, 0.010780369862914085, 0.010347677394747734], [0.057758353650569916, 0.13819283246994019, 0.15408456325531006, 0.27608534693717957, 0.07184857875108719, 0.11587436497211456, 0.0481133833527565, 0.05567890778183937, 0.041594069451093674, 0.0407695472240448], [0.08650293946266174, 0.11715130507946014, 0.12152113020420074, 0.14910613000392914, 0.09350644797086716, 0.11056236922740936, 0.08158127963542938, 0.0858914703130722, 0.0773548036813736, 0.07682216912508011], [0.08880747109651566, 0.11435990035533905, 0.1178206279873848, 0.13986290991306305, 0.09486860781908035, 0.10918447375297546, 0.08486345410346985, 0.08862783759832382, 0.08103254437446594, 0.08057219535112381], [0.1107851043343544, 0.07929348200559616, 0.07593090087175369, 0.060881175100803375, 0.1021522581577301, 0.08522257953882217, 0.11958005279302597, 0.11316371709108353, 0.1260068416595459, 0.12698383629322052], [0.11217041313648224, 0.07557202875614166, 0.07178028672933578, 0.05531080439686775, 0.10196733474731445, 0.08234993368387222, 0.12297346442937851, 0.1152610033750534, 0.13070502877235413, 0.13190963864326477], [0.10059209167957306, 0.09886102378368378, 0.09858324378728867, 0.09751736372709274, 0.10024362057447433, 0.09934504330158234, 0.10117589682340622, 0.10092053562402725, 0.10135995596647263, 0.1014011800289154], [0.11659007519483566, 0.06390748172998428, 0.05922459438443184, 0.039698608219623566, 0.10047157853841782, 0.07237306237220764, 0.13273274898529053, 0.12008735537528992, 0.1464398205280304, 0.14847470819950104], [0.11844281852245331, 0.029076948761940002, 0.024363256990909576, 0.009561759419739246, 0.08358889818191528, 0.03882325813174248, 0.15996046364307404, 0.12656310200691223, 0.20150887966156006, 0.20811060070991516], [0.11966951936483383, 0.05016302317380905, 0.04497648403048515, 0.025184784084558487, 0.09636320918798447, 0.05989747866988182, 0.14381738007068634, 0.1243663802742958, 0.16610991954803467, 0.16945184767246246]], [[0.004730344749987125, 0.07112251222133636, 0.5890817642211914, 0.33211174607276917, 0.0017960118129849434, 0.000709796673618257, 1.992471698031295e-05, 1.6515336028533056e-05, 0.0002018763480009511, 0.00020953555940650403], [0.0011452373582869768, 0.07088999450206757, 0.3096422553062439, 0.61248779296875, 0.0030011399649083614, 0.0027821825351566076, 2.0562688405334484e-06, 1.625045570108341e-06, 2.5238436137442477e-05, 2.258478525618557e-05], [0.004656804725527763, 0.12077438831329346, 0.2122335433959961, 0.605672299861908, 0.022799963131546974, 0.03316324204206467, 6.0765669331885874e-05, 4.988666114513762e-05, 0.0003158081090077758, 0.00027324724942445755], [0.008342222310602665, 0.043095335364341736, 0.011264852248132229, 0.07478689402341843, 0.1741204410791397, 0.669562578201294, 0.005276793614029884, 0.004527809098362923, 0.005022159777581692, 0.004000939894467592], [0.015582202933728695, 0.0234763752669096, 0.0049802460707724094, 0.022554734721779823, 0.17847414314746857, 0.6049799919128418, 0.05220653861761093, 0.0493023507297039, 0.0263060349971056, 0.022137358784675598], [0.029485715553164482, 0.013564838096499443, 0.0041442085057497025, 0.007762824185192585, 0.08558899164199829, 0.16486471891403198, 0.25262486934661865, 0.25457730889320374, 0.09674306213855743, 0.09064345061779022], [0.03111124411225319, 0.012999635189771652, 0.004519225098192692, 0.007398784626275301, 0.07104359567165375, 0.12433698773384094, 0.26730650663375854, 0.2781444787979126, 0.10397910326719284, 0.09916047751903534], [0.008872934617102146, 0.0015379461692646146, 0.0003339909890200943, 0.0005568937631323934, 0.02074042521417141, 0.04265706613659859, 0.36548912525177, 0.4135512709617615, 0.07457035779953003, 0.07169005274772644], [0.01866566576063633, 0.0029222986195236444, 0.00138885120395571, 0.0010882955975830555, 0.013507424853742123, 0.01472720317542553, 0.3461729884147644, 0.38134869933128357, 0.10775701701641083, 0.11242160946130753], [0.0995653048157692, 0.06357648223638535, 0.06169099360704422, 0.048924461007118225, 0.07345901429653168, 0.06420580297708511, 0.15932731330394745, 0.15515291690826416, 0.13529789447784424, 0.13879983127117157], [0.011439657770097256, 0.0007452258723787963, 0.0005587118212133646, 0.00019713252549991012, 0.0023337900638580322, 0.0014831267762929201, 0.35411548614501953, 0.41687992215156555, 0.09875167161226273, 0.11349529772996902]], [[0.09946759790182114, 0.15575404465198517, 0.4964655637741089, 0.16634875535964966, 0.02022646740078926, 0.007125060074031353, 0.006088475231081247, 0.0025585314724594355, 0.0223037488758564, 0.023661689832806587], [0.01715768687427044, 0.17099882662296295, 0.34554991126060486, 0.4055154323577881, 0.024181362241506577, 0.0314011387526989, 0.000843456422444433, 0.0007485501701012254, 0.0018948508659377694, 0.0017087941523641348], [0.01636715605854988, 0.17828623950481415, 0.25806736946105957, 0.4264422059059143, 0.040226515382528305, 0.0733814388513565, 0.00139991519972682, 0.001539906021207571, 0.002288689138367772, 0.0020006070844829082], [0.03376402705907822, 0.1315636932849884, 0.09099489450454712, 0.204570934176445, 0.13314422965049744, 0.31336525082588196, 0.023647179827094078, 0.03470354899764061, 0.018148209899663925, 0.016098033636808395], [0.043901488184928894, 0.07288028299808502, 0.04175111651420593, 0.08592743426561356, 0.1404232531785965, 0.29102662205696106, 0.0881161317229271, 0.1359926015138626, 0.05190427228808403, 0.0480768084526062], [0.07207684218883514, 0.045554447919130325, 0.03268533945083618, 0.03660200536251068, 0.08772623538970947, 0.09612967073917389, 0.1765781044960022, 0.19445395469665527, 0.12866419553756714, 0.1295291930437088], [0.05993638560175896, 0.04044906795024872, 0.02643907070159912, 0.03454228863120079, 0.08995656669139862, 0.11473264545202255, 0.179846853017807, 0.22360312938690186, 0.11555903404951096, 0.11493496596813202], [0.023829622194170952, 0.008342263288795948, 0.003988982643932104, 0.006127108354121447, 0.04136882349848747, 0.05974310636520386, 0.25061583518981934, 0.39509066939353943, 0.10469160974025726, 0.10620205849409103], [0.05464078113436699, 0.011209729127585888, 0.00907678809016943, 0.0061359768733382225, 0.028087126091122627, 0.017831826582551003, 0.2501251995563507, 0.2224743664264679, 0.19098813831806183, 0.2094300538301468], [0.13001123070716858, 0.07869268953800201, 0.08690362423658371, 0.05815708264708519, 0.0751437395811081, 0.04987401142716408, 0.12413031607866287, 0.09225102514028549, 0.14911608397960663, 0.15572014451026917], [0.04493717476725578, 0.00444316491484642, 0.00419613579288125, 0.0018679591594263911, 0.01162094809114933, 0.004743797704577446, 0.25874707102775574, 0.18647052347660065, 0.2229832410812378, 0.25999000668525696]], [[0.05810096114873886, 0.016580814495682716, 0.02330908551812172, 0.03557275980710983, 0.05468646436929703, 0.06514442712068558, 0.20391017198562622, 0.2593865692615509, 0.13733111321926117, 0.14597763121128082], [0.06333504617214203, 0.020423972979187965, 0.02767479233443737, 0.04063190519809723, 0.060247715562582016, 0.07077189534902573, 0.1948816329240799, 0.2408420592546463, 0.13679654896259308, 0.14439447224140167], [0.07833553105592728, 0.03693552315235138, 0.04517838731408119, 0.0583164319396019, 0.07582556456327438, 0.08440745621919632, 0.16514118015766144, 0.18996000289916992, 0.13056960701942444, 0.13533027470111847], [0.07871446758508682, 0.037721022963523865, 0.04602515324950218, 0.05901295691728592, 0.07606107741594315, 0.08433709293603897, 0.16413703560829163, 0.1888030767440796, 0.13023309409618378, 0.13495507836341858], [0.08361916989088058, 0.04585988074541092, 0.05400611087679863, 0.06611459702253342, 0.08119823038578033, 0.08826646208763123, 0.152801513671875, 0.17159460484981537, 0.12638497352600098, 0.13015444576740265], [0.07361150532960892, 0.03104175627231598, 0.039272382855415344, 0.052517037838697433, 0.07058573514223099, 0.07959393411874771, 0.17486606538295746, 0.2064444124698639, 0.13316583633422852, 0.13890135288238525], [0.0787796601653099, 0.03800720348954201, 0.04639086127281189, 0.059257686138153076, 0.07593734562397003, 0.0839838981628418, 0.1638624370098114, 0.18878333270549774, 0.13012582063674927, 0.1348717212677002], [0.08293075114488602, 0.04444175958633423, 0.05261218175292015, 0.06495732069015503, 0.08053919672966003, 0.08792167901992798, 0.15456286072731018, 0.17402970790863037, 0.12705688178539276, 0.13094760477542877], [0.08998521417379379, 0.0595046728849411, 0.06664558500051498, 0.07656121253967285, 0.08812520653009415, 0.09329263865947723, 0.1363670378923416, 0.14777810871601105, 0.11963934451341629, 0.12210104614496231], [0.07551287859678268, 0.03351167216897011, 0.04186002165079117, 0.05497957020998001, 0.07247821986675262, 0.08107143640518188, 0.17086994647979736, 0.20006558299064636, 0.1321304738521576, 0.1375201791524887], [0.10196925699710846, 0.12337372452020645, 0.1173512414097786, 0.10991550981998444, 0.10272809118032455, 0.09989979863166809, 0.0845382809638977, 0.08166301250457764, 0.08967586606740952, 0.08888516575098038]]], [[[0.006899794097989798, 0.2477148324251175, 0.42278239130973816, 0.2935366928577423, 0.012758998200297356, 0.014708587899804115, 0.00023062745458446443, 7.932886364869773e-05, 0.0006916138809174299, 0.0005971220089122653], [0.029886949807405472, 0.24621082842350006, 0.3375247120857239, 0.27476274967193604, 0.043207649141550064, 0.0472707562148571, 0.004076985642313957, 0.00219570635817945, 0.007753053214401007, 0.007110659498721361], [0.040510907769203186, 0.2368575632572174, 0.3083610236644745, 0.2612094581127167, 0.05541852116584778, 0.05996411666274071, 0.0076964860782027245, 0.004610305652022362, 0.013144501484930515, 0.01222709845751524], [0.09864182025194168, 0.0874302089214325, 0.08578529208898544, 0.08788805454969406, 0.09750969707965851, 0.09767737239599228, 0.11215336620807648, 0.1174226701259613, 0.10747352242469788, 0.10801800340414047], [0.09360753744840622, 0.06119605526328087, 0.057326532900333405, 0.06042225658893585, 0.08774883300065994, 0.08678161352872849, 0.14159289002418518, 0.16172945499420166, 0.12371640652418137, 0.12587842345237732], [0.09490121155977249, 0.06117260083556175, 0.057264141738414764, 0.059252772480249405, 0.0873754471540451, 0.0853303000330925, 0.1422739326953888, 0.1603199541568756, 0.12493234127759933, 0.12717729806900024], [0.0746973305940628, 0.028137551620602608, 0.02427845261991024, 0.026707978919148445, 0.06303141266107559, 0.06048627570271492, 0.18802714347839355, 0.24991628527641296, 0.13951744139194489, 0.1452002227306366], [0.03941299393773079, 0.006309135816991329, 0.0047964248806238174, 0.005831269547343254, 0.028964152559638023, 0.02709505707025528, 0.22650204598903656, 0.3940028250217438, 0.12852802872657776, 0.13855808973312378], [0.07935791462659836, 0.032518599182367325, 0.028455056250095367, 0.030617941170930862, 0.0672406405210495, 0.0642351508140564, 0.1814781129360199, 0.23267203569412231, 0.13913477957248688, 0.1442898064851761], [0.09829141944646835, 0.12794020771980286, 0.13315097987651825, 0.1280810534954071, 0.1019148975610733, 0.10226763039827347, 0.07550421357154846, 0.06907789409160614, 0.0823315754532814, 0.08144013583660126], [0.09365440160036087, 0.05601575970649719, 0.05188862606883049, 0.053524263203144073, 0.08443583548069, 0.081678606569767, 0.14895623922348022, 0.1701275110244751, 0.12850306928157806, 0.13121570646762848]], [[0.0071791233494877815, 0.9725857973098755, 0.01607443206012249, 0.0014460153179243207, 0.0015873407246544957, 0.0009801689302548766, 3.865058715746272e-06, 3.585590491184121e-07, 8.340532804140821e-05, 5.947089084656909e-05], [0.0903245285153389, 0.5183237791061401, 0.1616746336221695, 0.08271750062704086, 0.05305112153291702, 0.05808282643556595, 0.004446495324373245, 0.002792711602523923, 0.015234778635203838, 0.013351614587008953], [0.10956573486328125, 0.32504668831825256, 0.16847337782382965, 0.11917784810066223, 0.08295933157205582, 0.09446190297603607, 0.017338359728455544, 0.013837921433150768, 0.036042869091033936, 0.03309597447514534], [0.11025243997573853, 0.16559402644634247, 0.1297093629837036, 0.11873508244752884, 0.10630898922681808, 0.1162995770573616, 0.05710121616721153, 0.05261965095996857, 0.07298553735017776, 0.07039415836334229], [0.1060672476887703, 0.1612718254327774, 0.09572514146566391, 0.08008208125829697, 0.11853620409965515, 0.10788309574127197, 0.09396908432245255, 0.057890165597200394, 0.09064122289419174, 0.08793392032384872], [0.12008431553840637, 0.20865963399410248, 0.12945391237735748, 0.10040012001991272, 0.10573436319828033, 0.10198751837015152, 0.051965367048978806, 0.039312560111284256, 0.07266799360513687, 0.06973421573638916], [0.06143908202648163, 0.046979814767837524, 0.031497109681367874, 0.027557138353586197, 0.08394639939069748, 0.05361587181687355, 0.2833406329154968, 0.1319963037967682, 0.13717404007911682, 0.14245356619358063], [0.0021935480181127787, 0.0001402389898430556, 0.0012583243660628796, 0.004987930878996849, 0.006056598387658596, 0.007697666995227337, 0.2197762131690979, 0.6886102557182312, 0.0313744843006134, 0.03790472820401192], [0.06111945956945419, 0.03116440586745739, 0.043872226029634476, 0.051455382257699966, 0.07085692137479782, 0.06084836274385452, 0.2040470391511917, 0.21541890501976013, 0.12689779698848724, 0.1343195140361786], [0.11624686419963837, 0.1362054944038391, 0.10097473114728928, 0.07954096049070358, 0.1001269593834877, 0.08165346086025238, 0.09652897715568542, 0.07377462089061737, 0.10752891004085541, 0.1074189767241478], [0.07775713503360748, 0.04849639907479286, 0.05452904850244522, 0.053291670978069305, 0.07781744003295898, 0.05998755246400833, 0.1841658651828766, 0.16659274697303772, 0.1353142112493515, 0.1420479714870453]], [[1.3322221093403641e-05, 0.004385134670883417, 0.9915869235992432, 0.004014637786895037, 2.5530017211394807e-08, 4.1520382687565416e-09, 3.869115531435208e-12, 1.8261484175958326e-13, 5.644631428936009e-10, 4.65916860648008e-10], [0.00018109810480382293, 0.014525646343827248, 0.8777869939804077, 0.10749625414609909, 4.116519448871259e-06, 5.30698571310495e-06, 1.8233437870662783e-08, 9.95296556283165e-09, 2.95799225114024e-07, 2.488227153207845e-07], [0.0006723959813825786, 0.01917184889316559, 0.33402037620544434, 0.6450820565223694, 0.0001486120600020513, 0.0008453366463072598, 5.55781207367545e-06, 1.8016897229244933e-05, 1.9500241251080297e-05, 1.635157605051063e-05], [0.0036955378018319607, 0.014545023441314697, 0.0007249723421409726, 0.0029412948060780764, 0.2599561810493469, 0.7107717990875244, 0.0020775587763637304, 0.0006815873784944415, 0.002619915409013629, 0.0019860980100929737], [0.0012292788596823812, 0.003996782470494509, 0.00044435725430957973, 0.010004591196775436, 0.0760854184627533, 0.8847324252128601, 0.005639990791678429, 0.013153839856386185, 0.0026457547210156918, 0.002067585475742817], [0.03561485931277275, 0.010345223359763622, 0.0004844754876103252, 0.00024855980882421136, 0.40925464034080505, 0.12090273946523666, 0.15159259736537933, 0.020697005093097687, 0.12671397626399994, 0.12414587289094925], [0.006441198755055666, 0.002875629113987088, 0.0006637541227973998, 0.004473922774195671, 0.05320014804601669, 0.16108770668506622, 0.18706423044204712, 0.47748297452926636, 0.05392197147011757, 0.05278841778635979], [4.694412200478837e-05, 7.58864780436852e-06, 1.0160034662476392e-06, 5.4321641073329374e-05, 0.001239848555997014, 0.014015121385455132, 0.06417514383792877, 0.9120845198631287, 0.004153051879256964, 0.004222462419420481], [0.0435115285217762, 0.006075461860746145, 0.0011510126059874892, 0.00035075456253252923, 0.07135031372308731, 0.013861721381545067, 0.31699779629707336, 0.08319742232561111, 0.21841730177402496, 0.245086669921875], [0.05467931553721428, 0.007664982229471207, 0.0036452324129641056, 0.000922478677239269, 0.03227456659078598, 0.005779349245131016, 0.29471808671951294, 0.1139477863907814, 0.22389328479766846, 0.2624748945236206], [0.1513015180826187, 0.02515949308872223, 0.04100378602743149, 0.003383951261639595, 0.015663689002394676, 0.001469527487643063, 0.18074379861354828, 0.05553678050637245, 0.23476456105709076, 0.29097285866737366]], [[0.10389360785484314, 0.283723920583725, 0.5510646104812622, 0.04799244552850723, 0.006315154954791069, 0.0015484709292650223, 3.62124883395154e-05, 6.51256470973749e-08, 0.0027930026408284903, 0.002632524585351348], [0.10008838772773743, 0.25810444355010986, 0.3572256863117218, 0.14719052612781525, 0.04871425777673721, 0.04424802213907242, 0.004158926662057638, 0.0008291242993436754, 0.020365245640277863, 0.019075341522693634], [0.09001872688531876, 0.17763465642929077, 0.2118808776140213, 0.1714952439069748, 0.08990833908319473, 0.11761323362588882, 0.02793288230895996, 0.024719098582863808, 0.04550216719508171, 0.04329470545053482], [0.122281514108181, 0.15794409811496735, 0.16790984570980072, 0.12958939373493195, 0.09992609173059464, 0.09514506906270981, 0.04745740070939064, 0.02757563628256321, 0.07685650140047073, 0.07531440258026123], [0.15109069645404816, 0.13092441856861115, 0.14684784412384033, 0.12961114943027496, 0.09615723043680191, 0.06980627030134201, 0.05743666738271713, 0.012783641926944256, 0.10208645462989807, 0.10325559228658676], [0.1320624202489853, 0.11624855548143387, 0.1131238266825676, 0.0948479175567627, 0.10169202834367752, 0.0801997035741806, 0.0859762504696846, 0.04563821852207184, 0.11465585231781006, 0.11555522680282593], [0.09959270805120468, 0.0339265801012516, 0.03175735846161842, 0.046318549662828445, 0.07160241156816483, 0.04020106792449951, 0.23222734034061432, 0.062154024839401245, 0.1834220588207245, 0.19879794120788574], [4.165245991316624e-05, 2.122774822055362e-05, 1.4156704310153145e-05, 9.636285540182143e-05, 0.0003349913749843836, 0.0010109273716807365, 0.012402676977217197, 0.9849876761436462, 0.0005346204270608723, 0.0005557068507187068], [0.06556902825832367, 0.03746967762708664, 0.03252324089407921, 0.0427432581782341, 0.07154911756515503, 0.06097616255283356, 0.20001919567584991, 0.24061864614486694, 0.12177366763353348, 0.12675800919532776], [0.1294279843568802, 0.10830806940793991, 0.10629887133836746, 0.08734408020973206, 0.0968213826417923, 0.07455528527498245, 0.09600204974412918, 0.058033932000398636, 0.1206989735364914, 0.1225094199180603], [0.1350184679031372, 0.07025041431188583, 0.06623592227697372, 0.05911465734243393, 0.08366508036851883, 0.048361361026763916, 0.1436634510755539, 0.05364793539047241, 0.1655907928943634, 0.17445188760757446]]]], \"left_text\": [\"<sos>\", \"eine\", \"junge\", \"dame\", \"macht\", \"yoga\", \"am\", \"strand\", \".\", \"<eos>\"], \"right_text\": [\"<sos>\", \"a\", \"young\", \"lady\", \"doing\", \"yoga\", \"on\", \"the\", \"beach\", \".\", \"<eos>\"]}}, \"default_filter\": \"cross\"}",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "/**\n * @fileoverview Transformer Visualization D3 javascript code.\n *\n *\n *  Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n *\n * Change log:\n *\n * 12/19/18  Jesse Vig   Assorted cleanup. Changed orientation of attention matrices.\n */\n\nrequirejs(['jquery', 'd3'], function($, d3) {\n\nconst TEXT_SIZE = 15;\nconst BOXWIDTH = 130;\nconst BOXHEIGHT = 22.5;\nconst MATRIX_WIDTH = 115;\nconst CHECKBOX_SIZE = 20;\nconst TEXT_TOP = 30;\nconst HEAD_COLORS = d3.scale.category10();\n\nvar params = window.params;\nvar config = {};\ninitialize();\n\nfunction lighten(color) {\n  var c = d3.hsl(color);\n  var increment = (1 - c.l) * 0.6;\n  c.l += increment;\n  c.s -= increment;\n  return c;\n}\n\nfunction transpose(mat) {\n  return mat[0].map(function(col, i) {\n    return mat.map(function(row) {\n      return row[i];\n    });\n  });\n}\n\nfunction zip(a, b) {\n  return a.map(function (e, i) {\n    return [e, b[i]];\n  });\n}\n\nfunction render() {\n\n  var attnData = config.attention[config.filter];\n  var leftText = attnData.left_text;\n  var rightText = attnData.right_text;\n  var attentionHeads = attnData.attn[config.layer];\n\n  $(\"#vis svg\").empty();\n  $(\"#vis\").empty();\n\n  var height = config.initialTextLength * BOXHEIGHT + TEXT_TOP;\n  var svg = d3.select(\"#vis\")\n            .append('svg')\n            .attr(\"width\", \"100%\")\n            .attr(\"height\", height + \"px\");\n\n  var attData = [];\n  for (var i=0; i < config.nHeads; i++) {\n    var att = attentionHeads[i];\n    var att_trans = transpose(att);\n    attData.push(zip(att_trans, att));\n  }\n\n  renderText(svg, leftText, true, attData, 0);\n  renderText(svg, rightText, false, attData, MATRIX_WIDTH + BOXWIDTH);\n\n  renderAttentionHighlights(svg, attData);\n\n  svg.append(\"g\").classed(\"attentionHeads\", true);\n\n  renderAttention(svg, attentionHeads);\n\n  drawCheckboxes(0, svg, attentionHeads);\n\n}\n\nfunction renderText(svg, text, isLeft, attData, leftPos) {\n  // attData: list of tuples (att, att_trans), one for each layer. att and att_trans are attention matrics for each layer.\n  //           att is of shape [nHeads, source_len, target_len)\n  var id = isLeft ? \"left\" : \"right\";\n  var textContainer = svg.append(\"svg:g\")\n                         .attr(\"id\", id);\n\n  textContainer.append(\"g\").classed(\"attentionBoxes\", true)\n               .selectAll(\"g\")\n               .data(attData)\n               .enter()\n               .append(\"g\")\n               .selectAll(\"rect\")\n               .data(function(d) {return d;})\n               .enter()\n               .append(\"rect\")\n               .attr(\"x\", function(d, i, j) {\n                 return leftPos + boxOffsets(j);\n               })\n               .attr(\"y\", function(d, i) {\n                 return (+1) * BOXHEIGHT;\n               })\n               .attr(\"width\", BOXWIDTH / activeHeads())\n               .attr(\"height\", function() { return BOXHEIGHT; })\n               .attr(\"fill\", function(d, i, j) {\n                  return HEAD_COLORS(j);\n                })\n               .style(\"opacity\", 0.0);\n\n  var tokenContainer = textContainer.append(\"g\").selectAll(\"g\")\n                                    .data(text)\n                                    .enter()\n                                    .append(\"g\");\n\n  tokenContainer.append(\"rect\")\n                .classed(\"background\", true)\n                .style(\"opacity\", 0.0)\n                .attr(\"fill\", \"lightgray\")\n                .attr(\"x\", leftPos)\n                .attr(\"y\", function(d, i) {\n                  return TEXT_TOP + i * BOXHEIGHT;\n                })\n                .attr(\"width\", BOXWIDTH)\n                .attr(\"height\", BOXHEIGHT);\n\n  var textEl = tokenContainer.append(\"text\")\n                              .text(function(d) { return d; })\n                              .attr(\"font-size\", TEXT_SIZE + \"px\")\n                              .style(\"cursor\", \"default\")\n                              .style(\"-webkit-user-select\", \"none\")\n                              .attr(\"x\", leftPos)\n                              .attr(\"y\", function(d, i) {\n                                return TEXT_TOP + i * BOXHEIGHT;\n                              });\n\n  if (isLeft) {\n    textEl.style(\"text-anchor\", \"end\")\n           .attr(\"dx\", BOXWIDTH - 0.5 * TEXT_SIZE)\n           .attr(\"dy\", TEXT_SIZE);\n  } else {\n    textEl.style(\"text-anchor\", \"start\")\n           .attr(\"dx\", + 0.5 * TEXT_SIZE)\n           .attr(\"dy\", TEXT_SIZE);\n  }\n\n  tokenContainer.on(\"mouseover\", function(d, index) {\n    textContainer.selectAll(\".background\")\n                 .style(\"opacity\", function(d, i) {\n                   return i == index ? 1.0 : 0.0;\n                 });\n\n    svg.selectAll(\".attentionHeads\").style(\"display\", \"none\");\n\n    svg.selectAll(\".lineHeads\")  // To get the nesting to work.\n       .selectAll(\".attLines\")\n       .attr(\"stroke-opacity\", function(d) {\n          return 1.0;\n        })\n       .attr(\"y1\", function(d, i) {\n        if (isLeft) {\n          return TEXT_TOP + index * BOXHEIGHT + (BOXHEIGHT/2);\n        } else {\n          return TEXT_TOP + i * BOXHEIGHT + (BOXHEIGHT/2);\n        }\n     })\n     .attr(\"x1\", BOXWIDTH)\n     .attr(\"y2\", function(d, i) {\n       if (isLeft) {\n          return TEXT_TOP + i * BOXHEIGHT + (BOXHEIGHT/2);\n        } else {\n          return TEXT_TOP + index * BOXHEIGHT + (BOXHEIGHT/2);\n        }\n     })\n     .attr(\"x2\", BOXWIDTH + MATRIX_WIDTH)\n     .attr(\"stroke-width\", 2)\n     .attr(\"stroke\", function(d, i, j) {\n        return HEAD_COLORS(j);\n      })\n     .attr(\"stroke-opacity\", function(d, i, j) {\n      if (isLeft) {d = d[0];} else {d = d[1];}\n      if (config.headVis[j]) {\n        if (d) {\n          return d[index];\n        } else {\n          return 0.0;\n        }\n      } else {\n        return 0.0;\n      }\n     });\n\n    function updateAttentionBoxes() {\n      var id = isLeft ? \"right\" : \"left\";\n      var leftPos = isLeft ? MATRIX_WIDTH + BOXWIDTH : 0;\n      svg.select(\"#\" + id)\n         .selectAll(\".attentionBoxes\")\n         .selectAll(\"g\")\n         .selectAll(\"rect\")\n         .attr(\"x\", function(d, i, j) { return leftPos + boxOffsets(j); })\n         .attr(\"y\", function(d, i) { return TEXT_TOP + i * BOXHEIGHT; })\n         .attr(\"width\", BOXWIDTH/activeHeads())\n         .attr(\"height\", function() { return BOXHEIGHT; })\n         .style(\"opacity\", function(d, i, j) {\n            if (isLeft) {d = d[0];} else {d = d[1];}\n            if (config.headVis[j])\n              if (d) {\n                return d[index];\n              } else {\n                return 0.0;\n              }\n            else\n              return 0.0;\n         });\n    }\n\n    updateAttentionBoxes();\n  });\n\n  textContainer.on(\"mouseleave\", function() {\n    d3.select(this).selectAll(\".background\")\n                   .style(\"opacity\", 0.0);\n    svg.selectAll(\".attLines\").attr(\"stroke-opacity\", 0.0);\n    svg.selectAll(\".attentionHeads\").style(\"display\", \"inline\");\n    svg.selectAll(\".attentionBoxes\")\n       .selectAll(\"g\")\n       .selectAll(\"rect\")\n       .style(\"opacity\", 0.0);\n  });\n}\n\nfunction renderAttentionHighlights(svg, attention) {\n  var line_container = svg.append(\"g\");\n  line_container.selectAll(\"g\")\n                .data(attention)\n                .enter()\n                .append(\"g\")\n                .classed(\"lineHeads\", true)\n                .selectAll(\"line\")\n                .data(function(d){return d;})\n                .enter()\n                .append(\"line\").classed(\"attLines\", true);\n}\n\nfunction renderAttention(svg, attentionHeads) {\n  var line_container = svg.selectAll(\".attentionHeads\");\n  line_container.html(null);\n  for(var h=0; h<attentionHeads.length; h++) {\n    for(var s=0; s<attentionHeads[h].length; s++) {\n      for(var a=0; a<attentionHeads[h][s].length; a++) {\n        line_container.append(\"line\")\n        .attr(\"y1\", TEXT_TOP + s * BOXHEIGHT + (BOXHEIGHT/2))\n        .attr(\"x1\", BOXWIDTH)\n        .attr(\"y2\", TEXT_TOP + a * BOXHEIGHT + (BOXHEIGHT/2))\n        .attr(\"x2\", BOXWIDTH + MATRIX_WIDTH)\n        .attr(\"stroke-width\", 2)\n        .attr(\"stroke\", HEAD_COLORS(h))\n        .attr(\"stroke-opacity\", function() {\n          if (config.headVis[h]) {\n            return attentionHeads[h][s][a]/activeHeads();\n          } else {\n            return 0.0;\n          }\n        }());\n      }\n    }\n  }\n}\n\n// Checkboxes\nfunction boxOffsets(i) {\n  var numHeadsAbove = config.headVis.reduce(\n      function(acc, val, cur) {return val && cur < i ? acc + 1: acc;}, 0);\n  return numHeadsAbove * (BOXWIDTH / activeHeads());\n}\n\nfunction activeHeads() {\n  return config.headVis.reduce(function(acc, val) {\n    return val ? acc + 1: acc;\n  }, 0);\n}\n\nfunction drawCheckboxes(top, svg, attentionHeads) {\n  var checkboxContainer = svg.append(\"g\");\n  var checkbox = checkboxContainer.selectAll(\"rect\")\n                                  .data(config.headVis)\n                                  .enter()\n                                  .append(\"rect\")\n                                  .attr(\"fill\", function(d, i) {\n                                    return HEAD_COLORS(i);\n                                  })\n                                  .attr(\"x\", function(d, i) {\n                                    return i * CHECKBOX_SIZE;\n                                  })\n                                  .attr(\"y\", top)\n                                  .attr(\"width\", CHECKBOX_SIZE)\n                                  .attr(\"height\", CHECKBOX_SIZE);\n\n  function updateCheckboxes() {\n    checkboxContainer.selectAll(\"rect\")\n                              .data(config.headVis)\n                              .attr(\"fill\", function(d, i) {\n      var headColor = HEAD_COLORS(i);\n      var color = d ? headColor : lighten(headColor);\n      return color;\n    });\n  }\n\n  updateCheckboxes();\n\n  checkbox.on(\"click\", function(d, i) {\n    if (config.headVis[i] && activeHeads() == 1) return;\n    config.headVis[i] = !config.headVis[i];\n    updateCheckboxes();\n    renderAttention(svg, attentionHeads);\n  });\n\n  checkbox.on(\"dblclick\", function(d, i) {\n    // If we double click on the only active head then reset\n    if (config.headVis[i] && activeHeads() == 1) {\n      config.headVis = new Array(config.nHeads).fill(true);\n    } else {\n      config.headVis = new Array(config.nHeads).fill(false);\n      config.headVis[i] = true;\n    }\n    updateCheckboxes();\n    renderAttention(svg, attentionHeads);\n  });\n}\n\nfunction initialize() {\n  config.attention = params['attention'];\n  config.filter = params['default_filter'];\n  config.nLayers = config.attention[config.filter]['attn'].length;\n  console.log('num layers')\n  console.log(config.nLayers)\n  config.nHeads = config.attention[config.filter]['attn'][0].length;\n  config.headVis  = new Array(config.nHeads).fill(true);\n  config.layer = 0;\n  config.initialTextLength = Math.max(config.attention[config.filter].right_text.length,config.attention[config.filter].left_text.length);\n  console.log('initial text length')\n  console.log(config.initialTextLength)\n}\n\n$(\"#layer\").empty();\nfor(var i=1; i<config.nLayers+1; i++) {\n  $(\"#layer\").append($(\"<option />\").val(i-1).text(i));\n}\n\n$(\"#layer\").on('change', function(e) {\n  config.layer = +e.currentTarget.value;\n  render();\n});\n\n$(\"#filter\").on('change', function(e) {\n  config.filter = e.currentTarget.value;\n  render();\n});\n\nrender();\n\n});",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
   "source": [
    "SAMPLE_IDX = 131\n",
    "\n",
    "with torch.no_grad():\n",
    "  for idx,example in enumerate(test_iterator):\n",
    "    if idx == SAMPLE_IDX:\n",
    "      sample = example\n",
    "  src = sample.src\n",
    "  trg = sample.trg\n",
    "\n",
    "  output, enc_attention_score, dec_attention_score = model(src, trg) #turn off teacher forcing\n",
    "  attention_score = {'self':enc_attention_score, 'cross':dec_attention_score}\n",
<<<<<<< HEAD
    "\n",
    "  src_tok = [SRC.vocab.itos[x] for x in src.squeeze()]\n",
    "  trg_tok = [TRG.vocab.itos[x] for x in trg.squeeze()]\n",
=======
    "  print(output)\n",
    "  src_tok = [SRC.vocab.itos[x] for x in src.squeeze()]\n",
    "  trg_tok = [TRG.vocab.itos[x] for x in trg.squeeze()]\n",
    "  print(src_tok, trg_tok)\n",
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
    "\n",
    "  call_html()\n",
    "  head_view(attention_score, src_tok, trg_tok)"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './translation.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 1.966 | Test PPL:   7.140 |\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference (Search)\n",
    " Translator from https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/Translator.py\n",
    "\n",
    " https://github.com/dreamgonfly/transformer-pytorch\n",
    "use beam search !\n",
    "1. select top-K (beam size)\n",
    "2. Inference K times\n",
    "3. select top-k in K x |V| candidates for next timestep, where |V| is vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This module will handle the text generation with beam search. '''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformer.Models import Transformer, get_pad_mask, get_subsequent_mask\n",
    "\n",
    "\n",
    "class Translator(nn.Module):\n",
    "    ''' Load a trained model and translate in beam search fashion. '''\n",
    "\n",
    "    def __init__(\n",
    "            self, model, beam_size, max_seq_len,\n",
    "            src_pad_idx, trg_pad_idx, trg_bos_idx, trg_eos_idx):\n",
    "        \n",
    "\n",
    "        super(Translator, self).__init__()\n",
    "\n",
    "        self.alpha = 0.7\n",
    "        self.beam_size = beam_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_bos_idx = trg_bos_idx\n",
    "        self.trg_eos_idx = trg_eos_idx\n",
    "\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "        self.register_buffer('init_seq', torch.LongTensor([[trg_bos_idx]]))\n",
    "        self.register_buffer(\n",
    "            'blank_seqs', \n",
    "            torch.full((beam_size, max_seq_len), trg_pad_idx, dtype=torch.long))\n",
    "        self.blank_seqs[:, 0] = self.trg_bos_idx\n",
    "        self.register_buffer(\n",
    "            'len_map', \n",
    "            torch.arange(1, max_seq_len + 1, dtype=torch.long).unsqueeze(0))\n",
    "\n",
    "\n",
    "    def _model_decode(self, trg_seq, enc_output, src_mask):\n",
    "        trg_mask = get_subsequent_mask(trg_seq)\n",
    "        dec_output, *_ = self.model.decoder(trg_seq, trg_mask, enc_output, src_mask)\n",
    "        return F.softmax(self.model.trg_word_prj(dec_output), dim=-1)\n",
    "\n",
    "\n",
    "    def _get_init_state(self, src_seq, src_mask):\n",
    "        beam_size = self.beam_size\n",
    "\n",
    "        enc_output, *_ = self.model.encoder(src_seq, src_mask)\n",
    "        dec_output = self._model_decode(self.init_seq, enc_output, src_mask)\n",
    "        \n",
    "        best_k_probs, best_k_idx = dec_output[:, -1, :].topk(beam_size)\n",
    "\n",
    "        scores = torch.log(best_k_probs).view(beam_size)\n",
    "        gen_seq = self.blank_seqs.clone().detach()\n",
    "        gen_seq[:, 1] = best_k_idx[0]\n",
    "        enc_output = enc_output.repeat(beam_size, 1, 1)\n",
    "        return enc_output, gen_seq, scores\n",
    "\n",
    "\n",
    "    def _get_the_best_score_and_idx(self, gen_seq, dec_output, scores, step):\n",
    "        assert len(scores.size()) == 1\n",
    "        \n",
    "        beam_size = self.beam_size\n",
    "\n",
    "        # Get k candidates for each beam, k^2 candidates in total.\n",
    "        best_k2_probs, best_k2_idx = dec_output[:, -1, :].topk(beam_size)\n",
    "\n",
    "        # Include the previous scores.\n",
    "        scores = torch.log(best_k2_probs).view(beam_size, -1) + scores.view(beam_size, 1)\n",
    "\n",
    "        # Get the best k candidates from k^2 candidates.\n",
    "        scores, best_k_idx_in_k2 = scores.view(-1).topk(beam_size)\n",
    " \n",
    "        # Get the corresponding positions of the best k candidiates.\n",
    "        best_k_r_idxs, best_k_c_idxs = best_k_idx_in_k2 // beam_size, best_k_idx_in_k2 % beam_size\n",
    "        best_k_idx = best_k2_idx[best_k_r_idxs, best_k_c_idxs]\n",
    "\n",
    "        # Copy the corresponding previous tokens.\n",
    "        gen_seq[:, :step] = gen_seq[best_k_r_idxs, :step]\n",
    "        # Set the best tokens in this beam search step\n",
    "        gen_seq[:, step] = best_k_idx\n",
    "\n",
    "        return gen_seq, scores\n",
    "\n",
    "\n",
    "    def translate_sentence(self, src_seq):\n",
    "        # Only accept batch size equals to 1 in this function.\n",
    "        # TODO: expand to batch operation.\n",
    "        assert src_seq.size(0) == 1\n",
    "\n",
    "        src_pad_idx, trg_eos_idx = self.src_pad_idx, self.trg_eos_idx \n",
    "        max_seq_len, beam_size, alpha = self.max_seq_len, self.beam_size, self.alpha \n",
    "\n",
    "        with torch.no_grad():\n",
    "            src_mask = get_pad_mask(src_seq, src_pad_idx)\n",
    "            enc_output, gen_seq, scores = self._get_init_state(src_seq, src_mask)\n",
    "\n",
    "            ans_idx = 0   # default\n",
    "            for step in range(2, max_seq_len):    # decode up to max length\n",
    "                dec_output = self._model_decode(gen_seq[:, :step], enc_output, src_mask)\n",
    "                gen_seq, scores = self._get_the_best_score_and_idx(gen_seq, dec_output, scores, step)\n",
    "\n",
    "                # Check if all path finished\n",
    "                # -- locate the eos in the generated sequences\n",
    "                eos_locs = gen_seq == trg_eos_idx   \n",
    "                # -- replace the eos with its position for the length penalty use\n",
    "                seq_lens, _ = self.len_map.masked_fill(~eos_locs, max_seq_len).min(1)\n",
    "                # -- check if all beams contain eos\n",
    "                if (eos_locs.sum(1) > 0).sum(0).item() == beam_size:\n",
    "                    # TODO: Try different terminate conditions.\n",
    "                    _, ans_idx = scores.div(seq_lens.float() ** alpha).max(0)\n",
    "                    ans_idx = ans_idx.item()\n",
    "                    break\n",
    "        return gen_seq[ans_idx][:seq_lens[ans_idx]].tolist()"
   ]
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ai504_10_transformer.ipynb",
   "private_outputs": true,
   "provenance": []
  },
<<<<<<< HEAD
  "interpreter": {
   "hash": "98b183ca1800ea4e96dc3b796f78e5d640ebd4e2c7ed81e2a7c90e09c6123cdf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('LTML')",
=======
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:58:50) \n[GCC 10.3.0]"
=======
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3c07d0eca299da6e30653b2683f5b91d411ff0317449a715ca8f0962830e3d7"
   }
>>>>>>> 1bce3cecd0dc0816197b9b324d7e9a73d3d66f21
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
